{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries\n",
    "- `datetime` and `date` modules from the `datetime` library are imported to work with date and time objects.\n",
    "- `pandas` is imported as `pd`, a powerful library used for data manipulation and analysis, particularly to work with data structures like DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and merging data from Excel sheets\n",
    "- The Excel file `'COLECAO_ACARI.xlsx'` is loaded, which contains multiple sheets corresponding to different years of data.\n",
    "- The `sheet_name` list contains the names of the sheets, each representing data from the year 2012 to 2023.\n",
    "- The `pd.read_excel()` function is used to load the Excel file, with the `sheet_name` parameter set to the list of sheet names to load all sheets into a dictionary of DataFrames.\n",
    "  \n",
    "### Merging the sheets into a single DataFrame\n",
    "- The `pd.concat()` function is used to concatenate the DataFrames from each sheet into a single DataFrame, `df_darwincore`, combining data across all years.\n",
    "- The `ignore_index=True` argument ensures that the index is reset after concatenation.\n",
    "- The merged data is saved in two forms:\n",
    "  - `df_darwincore_antigo` holds the merged data for potential future reference.\n",
    "  - The `df_darwincore` DataFrame is written to a CSV file named `'original.csv'` without including the index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = 'COLECAO_ACARI.xlsx'\n",
    "sheet_name = [\n",
    "    'Planilha 2012 nova','Planilha 2013','Planilha 2014','Planilha 2015','Planilha 2016','Planilha 2017','Planilha 2018','Planilha 2019',\n",
    "    'Planilha 2020','Planilha 2021','Planilha 2022','Planilha 2023'\n",
    "]\n",
    "\n",
    "df = pd.read_excel(arquivo,sheet_name=sheet_name)\n",
    "\n",
    "# Unificar as planilhas\n",
    "df_darwincore = pd.concat(\n",
    "    [pd.DataFrame(df[sheet_name[0]]),pd.DataFrame(df[sheet_name[1]]),pd.DataFrame(df[sheet_name[2]]),pd.DataFrame(df[sheet_name[3]]),\n",
    "    pd.DataFrame(df[sheet_name[4]]),pd.DataFrame(df[sheet_name[5]]),pd.DataFrame(df[sheet_name[6]]),pd.DataFrame(df[sheet_name[7]]),\n",
    "    pd.DataFrame(df[sheet_name[8]]),pd.DataFrame(df[sheet_name[9]]),pd.DataFrame(df[sheet_name[10]]),pd.DataFrame(df[sheet_name[11]])],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_darwincore_antigo = df_darwincore\n",
    "df_darwincore.to_csv('original.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `itens_coluna()`\n",
    "- This function retrieves all unique values from a specified column of the `df_darwincore` DataFrame and writes them to a file, or prints them to the console if no filename is provided.\n",
    "\n",
    "#### Parameters:\n",
    "- `coluna` (string): The name of the column from which to extract unique values.\n",
    "- `nome_arquivo` (string or None): The name of the file where the unique values will be saved. If `None`, the values are printed to the console.\n",
    "\n",
    "#### Functionality:\n",
    "1. **Extract Unique Values**:\n",
    "   - The `df_darwincore[coluna].unique()` method retrieves unique values from the specified column.\n",
    "   - These values are sorted and converted into strings, with each value followed by a newline (`\\n`).\n",
    "\n",
    "2. **Write to File** (if `nome_arquivo` is provided):\n",
    "   - Opens the specified file in write mode (`\"w\"`) and writes the list of unique values.\n",
    "   - After writing, the file is closed to save changes.\n",
    "\n",
    "3. **Print Values** (if `nome_arquivo` is not provided):\n",
    "   - If no filename is provided, the unique values are printed to the console.\n",
    "\n",
    "### Function: `criar_lista()`\n",
    "- This function creates a list filled with a specified value, with the same length as the number of rows in the 'Tombo' column of the `df_darwincore` DataFrame.\n",
    "\n",
    "#### Parameters:\n",
    "- `conteudo`: The value to be repeated in the list.\n",
    "\n",
    "#### Returns:\n",
    "- `lista`: A list where each element is set to the specified `conteudo`, and the length of the list matches the number of rows in the 'Tombo' column of the DataFrame.\n",
    "\n",
    "#### Functionality:\n",
    "- The function multiplies the `conteudo` by the length of the 'Tombo' column (`len(df_darwincore['Tombo'])`), resulting in a list where every entry is the same as the `conteudo`.\n",
    "\n",
    "### Function: `muda_data()`\n",
    "- This function converts date strings from various formats into a standardized format (`YYYY-MM-DD`).\n",
    "\n",
    "#### Parameters:\n",
    "- `entry` (string): A date string that may be in various formats, such as `DD/MM/YYYY`, `MM/DD/YYYY`, or other combinations.\n",
    "\n",
    "#### Returns:\n",
    "- `entry` (string): The date string converted to the `YYYY-MM-DD` format, or left unchanged if no valid conversion is possible.\n",
    "\n",
    "#### Functionality:\n",
    "- The function handles multiple date formats and scenarios:\n",
    "  1. **Leap Year Handling**: Converts `29/02` to `02-29`.\n",
    "  2. **Specific Date Handling**: Converts `22/2014` to `2014-01-22`.\n",
    "  3. **General Date Conversion**: For valid `DD/MM/YY` and `DD/MM/YYYY` formats, it converts to `YYYY-MM-DD`.\n",
    "  4. **Ambiguous Formats**: Handles cases where the month and day could be swapped based on their values and lengths.\n",
    "  5. **Month-Year Formats**: Converts `MM/YYYY` to `YYYY-MM` and `DD/MM` to `MM-DD`.\n",
    "  6. **Date with Hyphens**: Converts dates in `DD-MM-YYYY` format to `YYYY-MM-DD`.\n",
    "\n",
    "- The function uses `datetime.strptime()` to parse the date strings and `strftime()` to format them.\n",
    "\n",
    "### Function: `adiciona_nova_info()`\n",
    "- This function adds new information to an existing cell value, ensuring that it is formatted correctly and does not duplicate existing content.\n",
    "\n",
    "#### Parameters:\n",
    "- `conteudo` (string): The new information to be added.\n",
    "- `celula` (string or NaN): The current value of the cell, which may be empty or contain existing data.\n",
    "\n",
    "#### Returns:\n",
    "- `celula` (string): The updated cell value, either with the new information appended or as the new value if the cell was previously empty.\n",
    "\n",
    "#### Functionality:\n",
    "- The function checks if `celula` has a value (is not `NaN` or empty) and is different from `conteudo`:\n",
    "  - If both conditions are met, it appends `conteudo` to `celula`, separated by a vertical bar (`|`).\n",
    "  - If either condition fails, it sets `celula` to `conteudo`.\n",
    "\n",
    "### Function: `ordem_alfabetica()`\n",
    "- This function organizes a string of items into alphabetical order, separated by a vertical bar (`|`).\n",
    "\n",
    "#### Parameters:\n",
    "- `entrada` (string): A string containing items that may be separated by the delimiter `|`.\n",
    "\n",
    "#### Returns:\n",
    "- `string`: The input string sorted alphabetically if it contains multiple items, or the original string if no sorting is required.\n",
    "\n",
    "#### Functionality:\n",
    "- The function checks if the input string contains the delimiter `|`:\n",
    "  - If true, it splits the string into a list of items using `split(' | ')`, sorts the list alphabetically, and then rejoins the sorted items into a single string using `join(' | ')`.\n",
    "  - If false, it simply returns the original `entrada` string, indicating that no sorting was needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar funções\n",
    "def itens_coluna(coluna,nome_arquivo):\n",
    "    lista=[]\n",
    "    for e in sorted(list(df_darwincore[coluna].unique())):\n",
    "        lista.append(str(e)+'\\n')\n",
    "\n",
    "    if nome_arquivo:\n",
    "        arquivo = open(nome_arquivo,\"w\") \n",
    "        arquivo.writelines(lista)\n",
    "        arquivo.close()\n",
    "\n",
    "    else:\n",
    "        print(lista)\n",
    "\n",
    "def criar_lista(conteudo):\n",
    "    lista = [conteudo] * len(df_darwincore['Tombo'])\n",
    "    return lista\n",
    "\n",
    "def muda_data(entry):\n",
    "    if len(entry.split('/'))>1 and entry.split('/')[0] == '29' and entry.split('/')[1] == '02':\n",
    "        entry = '02-29'\n",
    "\n",
    "    elif entry == '22/2014':\n",
    "        entry = '2014-01-22'\n",
    "\n",
    "    elif len(entry.split('/')) == 3 and len(entry.split('/')[0]) == 2 and len(entry.split('/')[1]) == 2:\n",
    "        if len(entry.split('/')[2]) == 2 and not entry.endswith('?'):\n",
    "            entry = datetime.strptime(entry,'%d/%m/%y').date().strftime('%Y-%m-%d')\n",
    "\n",
    "        elif len(entry.split('/')[2]) == 4:\n",
    "            entry = datetime.strptime(entry,'%d/%m/%Y').date().strftime('%Y-%m-%d')\n",
    "        \n",
    "        elif len(entry.split('/')[2]) == 0:\n",
    "            entry = datetime.strptime(entry,'%d/%m/').date().strftime('%m-%d')\n",
    "\n",
    "    elif len(entry.split('/')) == 3 and len(entry.split('/')[0]) == 1:\n",
    "        if  int(entry.split('/')[1]) <= 12 and len(entry.split('/')[2]) == 4:\n",
    "            entry = datetime.strptime(entry,'%d/%m/%Y').date().strftime('%Y-%m-%d')\n",
    "\n",
    "        elif int(entry.split('/')[1]) > 12 and len(entry.split('/')[2]) == 4:\n",
    "            entry = datetime.strptime(entry,'%m/%d/%Y').date().strftime('%Y-%m-%d')\n",
    "\n",
    "        elif len(entry.split('/')[2]) == 2 and int(entry.split('/')[1]) > 12:\n",
    "            entry = datetime.strptime(entry,'%d/%m/%y').date().strftime('%Y-%m-%d')\n",
    "\n",
    "        elif len(entry.split('/')[2]) == 2 and int(entry.split('/')[1]) <= 12:\n",
    "            entry = datetime.strptime(entry,'%d/%m/%y').date().strftime('%Y-%m-%d')\n",
    "\n",
    "    elif len(entry.split('/')) == 2 and len(entry.split('/')[0]) == 2:\n",
    "        if len(entry.split('/')[1]) == 4:\n",
    "            entry = datetime.strptime(entry,'%m/%Y').date().strftime('%Y-%m')\n",
    "\n",
    "        elif len(entry.split('/')[1]) == 2:\n",
    "            entry = datetime.strptime(entry,'%d/%m').date().strftime('%m-%d')\n",
    "\n",
    "    elif len(entry.split('-')) == 3 and len(entry.split('-')[0]) == 2 and len(entry.split('-')[1]) == 2 and len(entry.split('-')[2]) == 4:\n",
    "        entry = datetime.strptime(entry,'%d-%m-%Y').date().strftime('%Y-%m-%d')\n",
    "\n",
    "    return entry\n",
    "\n",
    "def adiciona_nova_info(conteudo,celula):\n",
    "    if celula and celula != 'nan' and celula != conteudo:\n",
    "        celula += ' | ' + conteudo\n",
    "    else:\n",
    "        celula = conteudo\n",
    "    return celula\n",
    "\n",
    "def ordem_alfabetica(entry):\n",
    "    if ' | ' in entry:\n",
    "        lista_alfabetica = entry.split(' | ')\n",
    "        lista_alfabetica.sort()\n",
    "        return ' | '.join(lista_alfabetica)\n",
    "    else:\n",
    "        return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following columns are not present in the file and represent terms from the Darwin Core (DwC) standard.\n",
    "\n",
    "basisOfRecord = criar_lista('PreservedSpecimen')\n",
    "modified = criar_lista(date.today())\n",
    "datasetName = criar_lista('Coleção de Ácaros do Centro de coleções taxonômicas (CCT) da Universidade Federal de Minas Gerais (UFMG)')\n",
    "tipe = criar_lista('PhysicalObject')\n",
    "language = criar_lista('pt')\n",
    "institutionCode = criar_lista('UFMG-CCT')\n",
    "collectionCode = criar_lista('UFMG-AC')\n",
    "license = criar_lista('CC BY NC')\n",
    "rightsHolder = criar_lista('Universidade Federal de Minas Gerais (UFMG)')\n",
    "dynamicProperties = criar_lista({})\n",
    "occurrenceID = criar_lista('Br:UFMG-CCT:UFMG-AC:')\n",
    "otherCatalogNumbers = criar_lista('')\n",
    "sex = criar_lista('')\n",
    "stage = criar_lista('')\n",
    "preparations = criar_lista('')\n",
    "disposition = criar_lista('Na coleção')\n",
    "identificationRemarks = criar_lista('')\n",
    "countryCode = criar_lista('')\n",
    "continent = criar_lista('')\n",
    "minimumElevationInMeters = criar_lista('')\n",
    "occurrenceRemarks = criar_lista('')\n",
    "habitat = criar_lista('')\n",
    "samplingEffort = criar_lista('')\n",
    "municipality = criar_lista('')\n",
    "island = criar_lista('')\n",
    "waterBody = criar_lista('')\n",
    "locality = criar_lista('')\n",
    "locationRemarks = criar_lista('')\n",
    "verbatimLatitude = criar_lista('')\n",
    "verbatimLongitude = criar_lista('')\n",
    "decimalLatitude = criar_lista('')\n",
    "decimalLongitude = criar_lista('')\n",
    "higherClassification = criar_lista('')\n",
    "kingdom = criar_lista('Animalia')\n",
    "phylum = criar_lista('Arthropoda')\n",
    "classe = criar_lista('Arachnida')\n",
    "order = criar_lista('')\n",
    "Subordem = criar_lista('')\n",
    "Subcoorte = criar_lista('')\n",
    "Superfamília = criar_lista('')\n",
    "family = criar_lista('')\n",
    "subfamily = criar_lista('')\n",
    "genus = criar_lista('')\n",
    "subgenus = criar_lista('')\n",
    "specificEpithet = criar_lista('')\n",
    "infraspecificEpithet = criar_lista('')\n",
    "scientificName = criar_lista('')\n",
    "scientificNameAuthorship = criar_lista('')\n",
    "taxonRank = criar_lista('')\n",
    "vernacularName = criar_lista('')\n",
    "taxonRemarks = criar_lista('')\n",
    "identificationQualifier = criar_lista('')\n",
    "identifiedBy = criar_lista('')\n",
    "datainicio = criar_lista('')\n",
    "datafinal = criar_lista('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Data to Strings\n",
    "- This code converts all columns in the `df_darwincore` DataFrame to string data type and removes any leading or trailing whitespace.\n",
    "\n",
    "#### Steps:\n",
    "1. **Retrieve Column Names**:\n",
    "   - A list of column names is created using `list(df_darwincore.columns)` and stored in the variable `listacoluna`.\n",
    "\n",
    "2. **Convert Columns to String**:\n",
    "   - A loop iterates through each column name in `listacoluna`.\n",
    "   - For each column, the data type is converted to string using `astype(str)`.\n",
    "\n",
    "3. **Strip Whitespace**:\n",
    "   - After conversion, the `str.strip()` method is applied to remove any leading or trailing whitespace from the string values in each column.\n",
    "\n",
    "#### Result:\n",
    "- This ensures that all data in the DataFrame is uniformly treated as strings, facilitating further processing and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter dados em string\n",
    "listacoluna=list(df_darwincore.columns)\n",
    "for coluna in listacoluna:\n",
    "    df_darwincore[coluna] = df_darwincore[coluna].astype(str)\n",
    "    df_darwincore[coluna] = df_darwincore[coluna].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing in the DataFrame\n",
    "\n",
    "This section of the code performs data standardization and correction in a DataFrame (`df_darwincore`), focusing on ensuring that the information is uniform and consistent. The process involves identifying and correcting entries across various columns using a predefined set of rules.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- **Standardize Entries**: The code aims to replace different representations of information (such as names and abbreviations) with standardized forms.\n",
    "  \n",
    "- **Associate Codes and Classifications**: For specific entries, codes and classifications are assigned based on defined rules.\n",
    "\n",
    "- **Maintain Data Consistency**: The integrity and relationships between dependent columns are preserved throughout the process.\n",
    "\n",
    "### Functionality\n",
    "\n",
    "1. **Initialization**: \n",
    "   - Control variables, such as `cont`, are initialized to assist in iterating over the DataFrame entries.\n",
    "   - Lists or dictionaries are used to store standardized values, codes, and other relevant information.\n",
    "\n",
    "2. **Loop Over the DataFrame**:\n",
    "   - A `for` loop iterates through the DataFrame entries, performing conditional checks on each entry.\n",
    "\n",
    "3. **Conditions and Assignments**:\n",
    "   - Each `if` condition checks whether the entry matches a specific value.\n",
    "   - When a match is found, the value is replaced with the standardized form, and the appropriate codes or classifications are assigned to the corresponding lists.\n",
    "\n",
    "4. **Handling Exceptions**:\n",
    "   - The code should include checks for special cases, such as null values or unexpected entries, ensuring that the process does not fail.\n",
    "\n",
    "5. **Updating the DataFrame**:\n",
    "   - After the loop, the standardized entries are saved back into the DataFrame in the appropriate columns.\n",
    "\n",
    "### Final Considerations\n",
    "\n",
    "This data processing procedure is crucial for ensuring the quality and consistency of the information, especially in contexts that require high precision, such as analyses based on the Darwin Core (DwC) format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna Tombo\n",
    "cont = 0\n",
    "for entry in df_darwincore['Tombo']:\n",
    "    if 'perdido' in entry:\n",
    "        entry = entry.replace('(perdido)','')\n",
    "        disposition[cont] = 'Perdido'\n",
    "\n",
    "    elif len(entry.split('-')) > 1:\n",
    "        lista = entry.split('-')\n",
    "        otherCatalogNumbers[cont] = adiciona_nova_info(lista[-1],otherCatalogNumbers[cont])\n",
    "\n",
    "    if not occurrenceID[cont].endswith(entry):\n",
    "        occurrenceID[cont] = str(occurrenceID[cont]+entry)\n",
    "\n",
    "    df_darwincore.iloc[cont,0] = 'UFMGAC-' + entry\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna sexo/estágio\n",
    "cont=0\n",
    "for entry in df_darwincore['Sexo/Estágio']:\n",
    "    if entry.split(' ')[0] == '1' or entry.split(' ')[0] == '2':\n",
    "        df_darwincore.iloc[cont,2] = adiciona_nova_info(entry.split(' ')[0],df_darwincore.iloc[cont,2])\n",
    "        entry = entry.replace('1 ','')\n",
    "        entry = entry.replace('2 ','')\n",
    "        df_darwincore.iloc[cont,1] = entry\n",
    "\n",
    "    if entry.capitalize() == 'Fêmea' or entry.capitalize() == 'Macho' or entry.capitalize() == 'Femea':\n",
    "        entry = entry.replace('em','êm')\n",
    "        sex[cont] = entry.capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    if entry == '♀':\n",
    "        sex[cont] = 'Fêmea'\n",
    "        entry = ''\n",
    "    \n",
    "    if entry == '♂':\n",
    "        sex[cont] = 'Macho'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    if entry == 'Macho em ecdise':\n",
    "        sex[cont] = 'Macho'\n",
    "        identificationRemarks[cont] = adiciona_nova_info('em ecdise',identificationRemarks[cont])\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry == 'Fêmea/Adulto' or entry == 'Fêmea adulta':\n",
    "        sex[cont] = 'Fêmea'\n",
    "        stage[cont] = 'Adulto'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split(' em '))>1 and entry.split(' em ')[0] == 'Macho':\n",
    "        entry = entry.replace(entry.split(' em ')[0],'')\n",
    "        sex[cont] = 'Macho'\n",
    "        identificationRemarks[cont] = adiciona_nova_info(entry,identificationRemarks[cont])\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split(' em '))>1 and entry.split(' em ')[0] == 'Deutoninfa':\n",
    "        entry = entry.replace(entry.split(' em ')[0],'')\n",
    "        stage[cont] = 'Deutoninfa'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry.capitalize() == 'Exúvia':\n",
    "        identificationRemarks[cont] = adiciona_nova_info('Exúvia',identificationRemarks[cont])\n",
    "        df_darwincore.iloc[cont,1] =''\n",
    "\n",
    "    elif len(entry.split(' '))>1 and entry.split(' ')[1] == '(macho':\n",
    "        identificationRemarks[cont] = adiciona_nova_info('(macho na descrição)',identificationRemarks[cont])\n",
    "        if entry.split(' ')[0] == 'Fêmea':\n",
    "            sex[cont] = entry.split(' ')[0].capitalize()\n",
    "        else:\n",
    "            stage[cont] = entry.split(' ')[0].capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry == 'Male':\n",
    "        sex[cont] = 'Macho'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "    \n",
    "    elif (\n",
    "        entry.capitalize() == 'Larva' or entry.capitalize() == 'Larvas' or entry.capitalize() == 'Larva ok'\n",
    "        or entry.capitalize() == 'Larvas ok'\n",
    "    ):\n",
    "        stage[cont] ='Larva'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry.capitalize() == 'Adulto' or entry.capitalize() == 'Adultos':\n",
    "        stage[cont] ='Adulto'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "    \n",
    "    elif entry.capitalize() == 'Deutoninfa' or entry.capitalize() == 'Dn':\n",
    "        stage[cont] ='Deutoninfa'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry == 'PN':\n",
    "        stage[cont] ='Protoninfa'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry.capitalize() == 'Protoninfa' or entry.capitalize() == 'Jovem' or entry.capitalize() == 'Tritoninfa':\n",
    "        stage[cont] = entry.capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry.capitalize() == 'Ninfa' or entry.capitalize() == 'Ninfas':\n",
    "        stage[cont] ='Ninfa'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry.capitalize() == 'Ovo' or entry.capitalize() == 'Ovos':\n",
    "        stage[cont] ='Ovo'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "    \n",
    "    elif entry.capitalize() == 'Pós larval' or entry.capitalize() == 'Pós larvais' or entry.capitalize() == 'Pós-larval':\n",
    "        stage[cont] ='Pós larval'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry.capitalize() == 'Perdido' or entry.capitalize() == 'Ácaro perdido':\n",
    "        disposition[cont] = 'Perdido'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split(' e '))>1 and entry.split(' e ')[0] == 'Fêmea':\n",
    "        sex[cont] = entry.split(' e ')[0].capitalize()\n",
    "        stage[cont] = entry.split(' e ')[-1].capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif (\n",
    "        len(entry.split(' e '))>1 and (entry.split(' e ')[0] == 'Adulto' or entry.split(' e ')[0] == 'Adultos'\n",
    "        or entry.split(' e ')[0] == 'Larva')\n",
    "    ):\n",
    "        stage[cont] = str(entry.split(' e ')[0].capitalize()+' | '+entry.split(' e ')[1].capitalize())\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split(' + '))>1 and (entry.split(' + ')[0] == 'Fêmea'):\n",
    "        sex[cont] = entry.split(' + ')[0].capitalize()\n",
    "        stage[cont] = entry.split(' + ')[-1].capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "    \n",
    "    elif len(entry.split(' '))>1 and entry.split(' ')[0] == 'Deutoninfa':\n",
    "        stage[cont] = 'Deutoninfa'\n",
    "        sex[cont] = entry.split(' ')[-1].capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split(' '))>1 and entry.split(' ')[0].capitalize() == 'Macho':\n",
    "        sex[cont] = 'Macho'\n",
    "        stage[cont] = entry.split(' ')[-1].capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split(' '))>1 and entry.split(' ')[0] == 'Ninfa':\n",
    "        stage[cont] = entry.split(' ')[0]\n",
    "        sex[cont] = entry.split(' ')[-1].capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split('-'))>1 and entry.split('-')[0] == 'Ninfa':\n",
    "        stage[cont] = entry.split('-')[0]\n",
    "        sex[cont] = entry.split('-')[-1].capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split('-'))>1 and 'DN' in entry.split('-'):\n",
    "        entry = entry.replace('DN','Deutoninfa')\n",
    "        entry = entry.replace('TN','Tritoninfa')\n",
    "        entry = entry.replace('PN','Protoninfa')\n",
    "        lista = entry.split('-')\n",
    "        stage[cont] = str(lista[0].capitalize()+' | '+lista[1].capitalize())\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "    \n",
    "    elif '-' in entry and 'ninfa' in entry:\n",
    "        stage[cont] = entry.replace('-',' | ')\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split(' + '))>1 and (entry.split(' + ')[1] == 'Macho' or entry.split(' + ')[1] == 'Fêmea'):\n",
    "        entry = entry.replace('DN','Deutoninfa')\n",
    "        stage[cont] = entry.split(' + ')[0]\n",
    "        sex[cont] = entry.split(' + ')[1].capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry == 'TN-Fêmea':\n",
    "        stage[cont] = 'Tritoninfa'\n",
    "        sex[cont] = 'Fêmea'\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif str(entry) == '3':\n",
    "        df_darwincore.iloc[cont,2] = adiciona_nova_info(entry,df_darwincore.iloc[cont,2])\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split(' ou '))>1 and entry.split(' ou ')[1] == 'macho':\n",
    "        stage[cont] = entry.split(' ou ')[0].capitalize()\n",
    "        sex[cont] = entry.split(' ou ')[1].capitalize()\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif len(entry.split('/'))>1:\n",
    "        stage[cont] = str(entry.split('/')[0].capitalize()+' | '+entry.split('/')[1].capitalize())\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif 'Perna' in entry or 'incompleto' in entry or 'Larva' in entry:\n",
    "        identificationRemarks[cont] = adiciona_nova_info(entry,identificationRemarks[cont])\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif 'em ecdise' in entry and 'proto' in entry:\n",
    "        entry = entry.replace('em ecdise','')\n",
    "        identificationRemarks[cont] = adiciona_nova_info('em ecdise',identificationRemarks[cont])\n",
    "        stage[cont] = entry\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    elif entry == 'nan':\n",
    "        df_darwincore.iloc[cont,1] = ''\n",
    "\n",
    "    cont+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna exemplares\n",
    "cont = 0\n",
    "for entry in df_darwincore['Exempl.']:\n",
    "    entry = entry.replace(' ind.','')\n",
    "    entry = entry.replace(' exemplares','')\n",
    "    entry = entry.replace(' exemplar','')\n",
    "    entry = entry.replace(' larvas','')\n",
    "    entry = entry.replace(' 1 de 3','')\n",
    "    entry = entry.replace(' 2 de 3','')\n",
    "    entry = entry.replace(' 3 de 3','')\n",
    "    entry = entry.replace('mais de ','>')\n",
    "    df_darwincore.iloc[cont,2] = entry.capitalize()\n",
    "    if entry.capitalize() == 'Perdido' or entry.split(' ')[-1].capitalize() == 'Perdido' or 'perdido' in entry.lower():\n",
    "        disposition[cont] = 'Perdido'\n",
    "        df_darwincore.iloc[cont,2] = ''\n",
    "\n",
    "    if entry == '1 (fóssil âmbar báltico)':\n",
    "        preparations[cont] = adiciona_nova_info('Fóssil âmbar báltico',preparations[cont])\n",
    "        basisOfRecord[cont] = 'FossilSpecimen'\n",
    "        df_darwincore.iloc[cont,2] = '1'\n",
    "\n",
    "    if entry == '1 (âmbar)' or entry == '2 (âmbar)':\n",
    "        preparations[cont] = adiciona_nova_info('Âmbar',preparations[cont])\n",
    "        basisOfRecord[cont] = 'FossilSpecimen'\n",
    "        df_darwincore.iloc[cont,2] = entry.split(' ')[0]\n",
    "\n",
    "    if entry == '1 (LÂMINA)':\n",
    "        preparations[cont] = adiciona_nova_info('Lâmina',preparations[cont])\n",
    "        df_darwincore.iloc[cont,2] = entry.split(' ')[0]\n",
    "\n",
    "    elif (\n",
    "        entry.capitalize() == 'Via úmida' or entry.capitalize() == 'Via umida' or entry.capitalize() == 'Via liquida'\n",
    "        or entry.capitalize() == 'Via líquida' or entry.capitalize() == 'Lamina' or entry.capitalize() == 'Lâmina'\n",
    "    ):\n",
    "        entry = entry.replace('via liquida','Via líquida')\n",
    "        entry = entry.replace('Via liquida','Via líquida')\n",
    "        entry = entry.replace('lamina','Lâmina')\n",
    "        entry = entry.replace('Lamina','Lâmina')\n",
    "        preparations[cont] = adiciona_nova_info(entry.capitalize(),preparations[cont])\n",
    "        df_darwincore.iloc[cont,2] = ''\n",
    "\n",
    "    elif (\n",
    "        entry.split('(')[-1].capitalize() == 'Via úmida)' or entry.split('(')[-1].capitalize() == 'Via umida)'\n",
    "        or entry.split('(')[-1] == 'via úmida)' or entry.split('(')[-1] == 'úmida)' or entry.split(' ')[-1] == 'úmida'\n",
    "        or entry.split(' ')[-1] == 'umida'\n",
    "    ):\n",
    "        preparations[cont] = adiciona_nova_info('Via úmida',preparations[cont])\n",
    "        entry = entry.replace('(via úmida)','')\n",
    "        entry = entry.replace('(Via úmida)','')\n",
    "        entry = entry.replace('(via umida)','')\n",
    "        entry = entry.replace('(Via umida)','')\n",
    "        entry = entry.replace('(úmida)','')\n",
    "        entry = entry.replace('via umida','')\n",
    "        entry = entry.replace('Via umida','')\n",
    "        entry = entry.replace('via úmida','')\n",
    "        entry = entry.replace('Via úmida','')\n",
    "        df_darwincore.iloc[cont,2] = entry\n",
    "\n",
    "    elif (entry.split('(')[-1].capitalize() == 'Via liquida)' or entry.split('(')[-1].capitalize() == 'Via líquida)'\n",
    "          or entry.split(' ')[-1] == 'líquida' or entry.split(' ')[-1] == 'liquida'\n",
    "    ):\n",
    "        preparations[cont] = adiciona_nova_info('Via líquida',preparations[cont])\n",
    "        entry = entry.replace('(via liquida)','')\n",
    "        entry = entry.replace('(Via liquida)','')\n",
    "        entry = entry.replace('(via líquida)','')\n",
    "        entry = entry.replace('(Via líquida)','')\n",
    "        entry = entry.replace('via liquida','')\n",
    "        entry = entry.replace('Via liquida','')\n",
    "        entry = entry.replace('via líquida','')\n",
    "        entry = entry.replace('Via líquida','')\n",
    "        df_darwincore.iloc[cont,2] = entry\n",
    "\n",
    "    elif (\n",
    "        entry.split('(')[-1].capitalize() == 'Lâmina)' or entry.split('(')[-1].capitalize() == 'Lamina)'\n",
    "        or entry.split('(')[-1] == 'via lâmina)' or entry.split(' ')[-1].capitalize() == 'Lâmina'\n",
    "        or entry.split(' ')[-1].capitalize() == 'Lamina' or entry.capitalize() == 'Extração'\n",
    "        or entry.split(' ')[-1].capitalize() == 'Extração' or entry.split('(')[-1].capitalize() == 'Extração)'\n",
    "    ):\n",
    "        preparations[cont] = adiciona_nova_info('Lâmina',preparations[cont])\n",
    "        entry = entry.replace('(Lâmina)','')\n",
    "        entry = entry.replace('(lâmina)','')\n",
    "        entry = entry.replace('(lamina)','')\n",
    "        entry = entry.replace('(Lamina)','')\n",
    "        entry = entry.replace('(via lâmina)','')\n",
    "        entry = entry.replace('Lâmina','')\n",
    "        entry = entry.replace('lâmina','')\n",
    "        entry = entry.replace('lamina','')\n",
    "        entry = entry.replace('Lamina','')\n",
    "        entry = entry.capitalize()\n",
    "        entry = entry.replace('(extração)','')\n",
    "        entry = entry.replace('extração','')\n",
    "        entry = entry.replace('Extração','')\n",
    "        df_darwincore.iloc[cont,2] = entry\n",
    "    \n",
    "    elif entry.capitalize() == 'Frasco':\n",
    "        preparations[cont] = adiciona_nova_info(entry.capitalize(),preparations[cont])\n",
    "        df_darwincore.iloc[cont,2] = ''\n",
    "\n",
    "    elif entry.split(' ')[-1] == 'criogenico' or entry.split(' ')[-1] == 'tymol)':\n",
    "        df_darwincore.iloc[cont,2] = entry.split(' ')[0]\n",
    "        entry = entry.replace('1 ','')\n",
    "        entry = entry.replace('3 ','')\n",
    "        preparations[cont] = adiciona_nova_info(entry.capitalize(),preparations[cont])\n",
    "        basisOfRecord[cont] = 'FossilSpecimen'\n",
    "\n",
    "    elif entry.split('(')[-1].lower() == 'perdido)' or entry.split('(')[-1] == 'voucher perdido)':\n",
    "        identificationRemarks[cont] = adiciona_nova_info('Perdido',identificationRemarks[cont])\n",
    "        entry = entry.replace('(perdido)','')\n",
    "        entry = entry.replace('(PERDIDO)','')\n",
    "        entry = entry.replace('(voucher perdido)','')\n",
    "        df_darwincore.iloc[cont,2] = entry\n",
    "\n",
    "    elif entry.split(' ')[-1] == 'later':\n",
    "        df_darwincore.iloc[cont,2] = entry.split(' ')[0]\n",
    "        entry = entry.replace('(via úmida ) rna later','')\n",
    "        preparations[cont] = adiciona_nova_info('Via úmida | RNA later',preparations[cont])\n",
    "\n",
    "    elif entry.split(' ')[-1] == 'grandes.':\n",
    "        df_darwincore.iloc[cont,2] = '4'\n",
    "        preparations[cont] = adiciona_nova_info('Frasco grande | Via úmida',preparations[cont])\n",
    "\n",
    "    elif entry.capitalize() == 'Exúvia':\n",
    "        identificationRemarks[cont] = adiciona_nova_info(entry.capitalize(),identificationRemarks[cont])\n",
    "        df_darwincore.iloc[cont,2] =''\n",
    "\n",
    "    elif entry == 'nan' or entry == '---' or 'Vários' in entry.capitalize() or entry == 'Muitos' or entry == 'Várias' or entry == 'varios':\n",
    "        df_darwincore.iloc[cont,2] = ''\n",
    "\n",
    "    if '(via úmida) esmagados' in entry:\n",
    "        entry = entry.replace('(via úmida) esmagados','')\n",
    "        preparations[cont] = adiciona_nova_info('Via úmida',preparations[cont])\n",
    "        occurrenceRemarks[cont] = adiciona_nova_info('Esmagados',occurrenceRemarks[cont])\n",
    "        df_darwincore.iloc[cont,2] = entry\n",
    "\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna ordem\n",
    "cont = 0\n",
    "for entry in df_darwincore['Ordem']:\n",
    "    entry = entry.replace(', ',' | ')\n",
    "    entry = entry.replace('/',' | ')\n",
    "    entry = entry.replace(' e ',' | ')\n",
    "    entry = entry.replace('  ',' ')\n",
    "    df_darwincore.iloc[cont,3] = entry\n",
    "    if entry.capitalize() == 'Perdido' or entry.split(' ')[-1].capitalize() == 'Perdido':\n",
    "        disposition[cont] = 'Perdido'\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'Sacorpitifomes' or entry == 'Sarcoptiforme':\n",
    "        entry = 'Sarcoptiformes'\n",
    "\n",
    "    elif entry == 'Não Ácaro':\n",
    "        taxonRemarks[cont] = 'Não Ácaro'\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or entry == '---' or entry == '????' or entry.capitalize() == 'Diversos' or entry == 'esquisito':\n",
    "        entry = ''\n",
    "    \n",
    "    entry = ordem_alfabetica(entry)\n",
    "    df_darwincore.iloc[cont,3] = entry.title()\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna subordem\n",
    "cont = 0\n",
    "for entry in df_darwincore['Subordem']:\n",
    "    entry = entry.replace('/',' | ')\n",
    "    if entry.capitalize() == 'Perdido' or (len(entry.split(' '))>1 and entry.split(' ')[1].capitalize() == 'Perdido'):\n",
    "        disposition[cont] = 'Perdido'\n",
    "        entry = ''\n",
    "\n",
    "    elif 'qiaamp' in entry:\n",
    "        identificationRemarks[cont] = adiciona_nova_info(entry,identificationRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or '--' in entry or entry == 'Vazio':\n",
    "        entry = ''\n",
    "\n",
    "    entry = ordem_alfabetica(entry)\n",
    "    df_darwincore.iloc[cont,4] = entry\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna coorte\n",
    "cont = 0\n",
    "for entry in df_darwincore['Coorte ou Supercoorte']:\n",
    "    entry = entry.replace('/',' | ')\n",
    "    if entry.capitalize() == 'Perdido' or (len(entry.split(' '))>1 and entry.split(' ')[1].capitalize() == 'Perdido'):\n",
    "        disposition[cont] = 'Perdido'\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or '--' in entry:\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,5] = entry\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna superfamilia\n",
    "cont = 0\n",
    "for entry in df_darwincore['Superfamília']:\n",
    "    entry = entry.replace('/',' | ')\n",
    "    entry = entry.replace(' ou ',' | ')\n",
    "    if entry.capitalize() == 'Perdido' or (len(entry.split(' '))>1 and entry.split(' ')[1].capitalize() == 'Perdido'):\n",
    "        disposition[cont] = 'Perdido'\n",
    "        entry = ''\n",
    "    \n",
    "    if '(' in entry:\n",
    "        entry.replace('(','')\n",
    "        entry.replace(')','')\n",
    "\n",
    "    elif entry == 'nan' or entry == '--' or entry == '---' or entry == '???':\n",
    "        entry = ''\n",
    "\n",
    "    entry = ordem_alfabetica(entry)\n",
    "    df_darwincore.iloc[cont,6] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna familia\n",
    "cont = 0\n",
    "for entry in df_darwincore['Família']:\n",
    "    entry = entry.replace(' + ',' | ')\n",
    "    entry = entry.replace(', ',' | ')\n",
    "    entry = entry.replace(' e ',' | ')\n",
    "    entry = entry.replace('/',' | ')\n",
    "\n",
    "    if entry.capitalize() == 'Perdido' or entry.split(' ')[-1].capitalize() == 'Perdido':\n",
    "        disposition[cont] = 'Perdido'\n",
    "        entry = ''\n",
    "\n",
    "    elif 'Aff.' in entry or 'cf' in entry:\n",
    "        taxonRemarks[cont] = adiciona_nova_info(entry,taxonRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or entry == '--' or entry == '---' or entry == '?????' or entry == 'Muito importante!':\n",
    "        entry = ''\n",
    "\n",
    "    if entry == entry.lower() and entry != '':\n",
    "        entry = entry.capitalize()\n",
    "\n",
    "    entry = ordem_alfabetica(entry)\n",
    "    df_darwincore.iloc[cont,7] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna subfamilia\n",
    "cont = 0\n",
    "for entry in df_darwincore['Subfamilia']:\n",
    "    entry = entry.replace(' e ',' | ')\n",
    "    entry = entry.replace(', ',' | ')\n",
    "    if entry.capitalize() == 'Perdido' or (len(entry.split(' '))>1 and entry.split(' ')[1].capitalize() == 'Perdido'):\n",
    "        disposition[cont] = 'Perdido'\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or entry == '--' or entry == '---' or entry == '0' or entry == '???' or entry == 'Vazio':\n",
    "        entry = ''\n",
    "\n",
    "    if 'com ' in entry:\n",
    "        entry = entry.replace('com ','')\n",
    "\n",
    "    if entry == entry.lower() and entry != '':\n",
    "        entry = entry.capitalize()\n",
    "\n",
    "    entry = ordem_alfabetica(entry)\n",
    "    df_darwincore.iloc[cont,8] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna genero\n",
    "cont = 0\n",
    "import re\n",
    "for entry in df_darwincore['Gênero']:\n",
    "    # regex para extrair o subgenero\n",
    "    result = re.match(r'^(.*?) \\((.*?)\\)$', entry)\n",
    "    if result:\n",
    "        entry = result.group(1)\n",
    "        subgenus[cont] = result.group(2)\n",
    "\n",
    "    entry = entry.replace(', ',' | ')\n",
    "    entry = entry.replace(' e ',' | ')\n",
    "\n",
    "    if (\n",
    "        entry.split(' ')[0].capitalize() == 'Gen' or entry.split(' ')[0].capitalize() == 'Gen.' or entry == 'Gênero novo'\n",
    "        or entry .split('.')[0].capitalize() == 'Gen' or 'aff' in entry.split(' ') or 'sp' in entry.split(' ') or 'cf' in entry.split(' ')\n",
    "        or 'cf.' in entry.split(' ')\n",
    "    ):\n",
    "        taxonRemarks[cont] = adiciona_nova_info(entry,taxonRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry.capitalize() == 'Perdido' or entry.split(' ')[-1].capitalize() == 'Perdido':\n",
    "        disposition[cont] = 'Perdido'\n",
    "        entry = ''\n",
    "    \n",
    "    elif entry == 'Estragado':\n",
    "        occurrenceRemarks[cont] = adiciona_nova_info(entry,occurrenceRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or entry == '--' or entry == '---':\n",
    "        entry = ''\n",
    "\n",
    "    entry = ordem_alfabetica(entry)\n",
    "    df_darwincore.iloc[cont,9] = entry.title()\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colune especie\n",
    "cont = 0\n",
    "for entry in df_darwincore['Espécie']:\n",
    "    entry = entry.lower()\n",
    "    entry = entry.replace('/',' | ')\n",
    "    if 'perdido' in entry or entry == 'não encontrado':\n",
    "        disposition[cont] = 'Perdido'\n",
    "        entry = ''\n",
    "\n",
    "    if ('incompleto' in entry or 'fragmentado' in entry or 'ruim' in entry or 'identificada' in entry or entry == 'pedaço de inseto'\n",
    "        or entry == 'pequeno' or entry == 'Sem óstias' or entry == 'Tardigrado'\n",
    "        ):\n",
    "        identificationRemarks[cont] = adiciona_nova_info(entry,identificationRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry.capitalize() == 'Não ácaro' or entry == 'diferentão' or entry == 'grandão':\n",
    "        taxonRemarks[cont] = adiciona_nova_info(entry,taxonRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif (\n",
    "        '--' in entry or '---' in entry or '----' in entry or entry == '.' or entry == 'gênero novo' or\n",
    "        entry == 'nan' or entry == '?'\n",
    "    ):\n",
    "        entry = ''\n",
    "\n",
    "    elif (\n",
    "        'aff' in entry.split(' ') or 'aff.' in entry.split(' ') or '(aff' in entry or 'cf' in entry.split(' ') or\n",
    "        'cf.' in entry.split(' ') or 'sp' in entry.split(' ') or 'sp' in entry.split('.') or 'sp,' in entry or\n",
    "        'sp.' in entry or 'sp1' in entry or 'sp2' in entry or 'sp3' in entry or 'sp4' in entry or 'sp5' in entry or entry == 'ops' or\n",
    "        'sp6' in entry or 'sp7' in entry or entry == 'a' or '?' in entry or entry.endswith('1') or entry.endswith('2') or entry.endswith('3')\n",
    "        or entry.endswith('4') or entry.endswith('5') or entry == 'hyd' or entry == 'y' or 'gr.' in entry or 'grupo' in entry\n",
    "    ):\n",
    "        taxonRemarks[cont] = adiciona_nova_info(entry,taxonRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    entry = ordem_alfabetica(entry)\n",
    "    df_darwincore.iloc[cont,10] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna autor e ano\n",
    "cont = 0\n",
    "for entry in df_darwincore['Autor e ano']:\n",
    "    entry = entry.replace('et al ','et. al. ')\n",
    "    entry = entry.replace('et. al ','et. al. ')\n",
    "    entry = entry.replace('et al. ','et. al. ')\n",
    "    entry = entry.replace(' & ',' | ')\n",
    "    entry = entry.replace(' and ',' | ')\n",
    "    entry = entry.replace(',1',' 1')\n",
    "    entry = entry.replace(', ','; ')\n",
    "    entry = entry.replace('o; T','o | T')\n",
    "    entry = entry.replace(' ?','')\n",
    "    if 'AC' in entry:\n",
    "        df_darwincore.iloc[cont,12] = adiciona_nova_info(entry,df_darwincore.iloc[cont,12])\n",
    "        entry = ''\n",
    "    \n",
    "    elif '(submetido)' in entry:\n",
    "        entry  = entry.replace('(submetido)','')\n",
    "\n",
    "    elif entry == 'muito incompleto' or entry == 'Destruido':\n",
    "        identificationRemarks[cont] = adiciona_nova_info(entry,identificationRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif 'e um' in entry.lower():\n",
    "        taxonRemarks[cont] = adiciona_nova_info(entry,taxonRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry.split(' ')[-1].capitalize() == 'Perdido':\n",
    "        disposition[cont] = 'Perdido'\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or entry == 'ok' or entry == 'Gênero novo':\n",
    "        entry = ''\n",
    "\n",
    "    elif '; ' in entry:\n",
    "        entry = entry.replace('; ',', ')\n",
    "\n",
    "    if entry.endswith('.)'):\n",
    "        entry = entry.replace('.','')\n",
    "\n",
    "    if entry and not entry.endswith(')'):\n",
    "        entry = '('+entry+')'\n",
    "\n",
    "    df_darwincore.iloc[cont,11] = entry\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna codigo\n",
    "cont = 0\n",
    "for entry in df_darwincore['Código']:\n",
    "    entry = entry.replace(';','-')\n",
    "    if entry == 'nan' or entry == 'gênero novo':\n",
    "        entry = ''\n",
    "\n",
    "    elif 'nan' in entry:\n",
    "        entry = entry.replace('nan | ','')\n",
    "\n",
    "    otherCatalogNumbers[cont] = adiciona_nova_info(entry,otherCatalogNumbers[cont])\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna determinador\n",
    "cont = 0\n",
    "lista_coletores = pd.read_csv('nomes.txt',delimiter=':',header=None)\n",
    "lista_coletores = pd.DataFrame(lista_coletores)\n",
    "for entry in df_darwincore['Determinador']:\n",
    "    if entry in list(lista_coletores[0]):\n",
    "        posicao = list(lista_coletores[0]).index(entry)\n",
    "        entry = lista_coletores.iloc[posicao,1]\n",
    "    \n",
    "    elif 'OK' in entry or 'Gênero' in entry or entry == 'nan':\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,13] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna ano determinacao\n",
    "cont = 0\n",
    "for entry in df_darwincore['Ano determinação']:\n",
    "    entry = entry.replace(')','')\n",
    "    entry = entry.replace('.0','')\n",
    "    if entry == 'nan' or entry == 'Gênero novo':\n",
    "        entry = ''\n",
    "    \n",
    "    elif '-' in entry:\n",
    "        entry = entry.replace('-','/20')\n",
    "\n",
    "    df_darwincore.iloc[cont,14] = entry\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna pais\n",
    "cont = 0\n",
    "for entry in df_darwincore['País']:\n",
    "    if entry == 'Brasil' or entry == 'Brazil' or entry == 'brasil':\n",
    "        countryCode[cont] = 'BRA'\n",
    "        continent[cont] = 'América do Sul'\n",
    "        entry = 'Brasil'\n",
    "\n",
    "    elif entry == 'Alemanha':\n",
    "        countryCode[cont] = 'DEU'\n",
    "        continent[cont] = 'Europa'\n",
    "        entry = 'Alemanha'\n",
    "\n",
    "    elif entry == 'Australia' or entry == 'Austrália':\n",
    "        countryCode[cont] = 'AUS'\n",
    "        continent[cont] = 'Oceania'\n",
    "        entry = 'Austrália'\n",
    "\n",
    "    elif entry == 'Azerbaijão':\n",
    "        countryCode[cont] = 'AZE'\n",
    "        continent[cont] = 'Ásia'\n",
    "        entry = 'Azerbaijão'\n",
    "\n",
    "    elif entry == 'Bolívia' or entry == 'Bolivia':\n",
    "        countryCode[cont] = 'BOL'\n",
    "        continent[cont] = 'América do Sul'\n",
    "        entry = 'Bolívia'\n",
    "    \n",
    "    elif entry == 'Chile':\n",
    "        countryCode[cont] = 'CHL'\n",
    "        continent[cont] = 'América do Sul'\n",
    "        entry = 'Chile'\n",
    "\n",
    "    elif entry == 'Cuba':\n",
    "        countryCode[cont] = 'CUB'\n",
    "        continent[cont] = 'América Central'\n",
    "        entry = 'Cuba'\n",
    "\n",
    "    elif entry == 'Equador':\n",
    "        countryCode[cont] = 'ECU'\n",
    "        continent[cont] = 'América do Sul'\n",
    "        entry = 'Equador'\n",
    "\n",
    "    elif entry == 'Espanha':\n",
    "        countryCode[cont] = 'ESP'\n",
    "        continent[cont] = 'Europa'\n",
    "        entry = 'Espanha'\n",
    "\n",
    "    elif entry == 'EUA' or entry == 'USA':\n",
    "        countryCode[cont] = 'USA'\n",
    "        continent[cont] = 'América do Norte'\n",
    "        entry = 'Estados Unidos'\n",
    "    \n",
    "    elif entry == 'Guiana Francesa':\n",
    "        countryCode[cont] = 'GUF'\n",
    "        continent[cont] = 'América do Sul'\n",
    "        entry = 'Guiana Francesa'\n",
    "\n",
    "    elif entry == 'Honduras':\n",
    "        countryCode[cont] = 'HND'\n",
    "        continent[cont] = 'América Central'\n",
    "        entry = 'Honduras'\n",
    "\n",
    "    elif entry == 'Iran':\n",
    "        countryCode[cont] = 'IRN'\n",
    "        continent[cont] = 'Ásia'\n",
    "        entry = 'Irã'\n",
    "\n",
    "    elif entry == 'Myanmar':\n",
    "        countryCode[cont] = 'MMR'\n",
    "        continent[cont] = 'Ásia'\n",
    "        entry = 'Myanmar'\n",
    "\n",
    "    elif entry == 'Myanmar, Cretáceo':\n",
    "        countryCode[cont] = 'MMR'\n",
    "        continent[cont] = 'Ásia'\n",
    "        occurrenceRemarks[cont] = adiciona_nova_info('Cretáceo',occurrenceRemarks[cont])\n",
    "        entry = 'Myanmar'\n",
    "\n",
    "    elif entry == 'Nova Zelândia':\n",
    "        countryCode[cont] = 'NZL'\n",
    "        continent[cont] = 'Oceania'\n",
    "        entry = 'Nova Zelândia'\n",
    "\n",
    "    elif entry == 'Panamá':\n",
    "        countryCode[cont] = 'PAN'\n",
    "        continent[cont] = 'América Central'\n",
    "        entry = 'Panamá'\n",
    "\n",
    "    elif entry == 'Peru':\n",
    "        countryCode[cont] = 'PER'\n",
    "        continent[cont] = 'América do Sul'\n",
    "        entry = 'Peru'\n",
    "\n",
    "    elif entry == 'Rússia' or entry == 'Russia':\n",
    "        countryCode[cont] = 'RUS'\n",
    "        continent[cont] = 'Ásia'\n",
    "        entry = 'Rússia'\n",
    "\n",
    "    elif entry == 'Tajiquistão':\n",
    "        countryCode[cont] = 'TJK'\n",
    "        continent[cont] = 'Ásia'\n",
    "        entry = 'Tajiquistão'\n",
    "\n",
    "    elif entry == 'Hamburg/Germany':\n",
    "        df_darwincore.iloc[cont,17] = adiciona_nova_info('Hamburgo',df_darwincore.iloc[cont,17])\n",
    "        countryCode[cont] = 'DEU'\n",
    "        continent[cont] = 'Europa'\n",
    "        entry = 'Alemanha'\n",
    "\n",
    "    elif entry == 'nan':\n",
    "        entry = ''\n",
    "    \n",
    "    df_darwincore.iloc[cont,15] = entry\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna estado\n",
    "cont = 0\n",
    "for entry in df_darwincore['U.F./Província/Região']:\n",
    "    if entry == 'AC':\n",
    "        entry = 'Acre'\n",
    "\n",
    "    elif entry == 'AL':\n",
    "        entry = 'Alagoas'\n",
    "\n",
    "    elif entry == 'AM':\n",
    "        entry = 'Amazonas'\n",
    "\n",
    "    elif entry == 'Araucánia' or entry == 'Araucania':\n",
    "        entry = 'Araucánia'\n",
    "\n",
    "    elif entry == 'BA' or entry == 'Bahia':\n",
    "        entry = 'Bahia'\n",
    "\n",
    "    elif entry == 'CA':\n",
    "        entry = 'California'\n",
    "\n",
    "    elif entry == 'CE':\n",
    "        entry = 'Ceará'\n",
    "\n",
    "    elif entry == 'Criméia' or entry == 'Crimeia':\n",
    "        entry = 'Crimeia'\n",
    "\n",
    "    elif entry == 'ES' or entry == 'Espirito Santo' or entry == 'Espirito Santos':\n",
    "        entry = 'Espírito Santo'\n",
    "\n",
    "    elif entry == 'MA' and df_darwincore.iloc[cont,15] == 'Brasil':\n",
    "        entry = 'Maranhão'\n",
    "\n",
    "    elif entry == 'MA':\n",
    "        entry = 'Massachusetts'\n",
    "\n",
    "    elif entry == 'MG' and df_darwincore.iloc[cont,15] != 'Brasil':\n",
    "        df_darwincore.iloc[cont,15] = 'Brasil'\n",
    "        countryCode[cont] = 'BRA'\n",
    "        continent[cont] = 'América do Sul'\n",
    "        entry = 'Minas Gerais'\n",
    "\n",
    "    elif entry == 'MG':\n",
    "        entry = 'Minas Gerais'\n",
    "\n",
    "    elif entry == 'MG/SP':\n",
    "        entry = 'Minas Gerais | São Paulo'\n",
    "\n",
    "    elif entry == 'MI':\n",
    "        entry = 'Michigan'\n",
    "\n",
    "    elif entry == 'MS':\n",
    "        entry = 'Mato Grosso do Sul'\n",
    "\n",
    "    elif entry == 'MT':\n",
    "        entry = 'Mato Grosso'\n",
    "\n",
    "    elif entry == 'NSW':\n",
    "        entry = 'Nova Gales do Sul'\n",
    "\n",
    "    elif entry == 'OH':\n",
    "        entry = 'Ohio'\n",
    "\n",
    "    elif entry == 'PA':\n",
    "        entry = 'Pará'\n",
    "\n",
    "    elif entry == 'PB' or entry == 'Paraiba':\n",
    "        entry = 'Paraíba'\n",
    "\n",
    "    elif entry == 'PE':\n",
    "        entry = 'Pernambuco'\n",
    "\n",
    "    elif entry == 'PI':\n",
    "        entry = 'Piauí'\n",
    "\n",
    "    elif entry == 'PR':\n",
    "        entry = 'Paraná'\n",
    "\n",
    "    elif entry == 'QLD':\n",
    "        entry = 'Queensland'\n",
    "\n",
    "    elif entry == 'RI':\n",
    "        entry = 'Rhode Island'\n",
    "\n",
    "    elif entry == 'RJ':\n",
    "        entry = 'Rio de Janeiro'\n",
    "\n",
    "    elif entry == 'RN':\n",
    "        entry = 'Rio Grande do Norte'\n",
    "\n",
    "    elif entry == 'RO':\n",
    "        entry = 'Rondônia'\n",
    "\n",
    "    elif entry == 'RS':\n",
    "        entry = 'Rio Grande do Sul'\n",
    "\n",
    "    elif entry == 'SC':\n",
    "        entry = 'Santa Catarina'\n",
    "\n",
    "    elif entry == 'SE':\n",
    "        entry = 'Sergipe'\n",
    "\n",
    "    elif entry == 'SP':\n",
    "        entry = 'São Paulo'\n",
    "\n",
    "    elif entry == 'Spn':\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'Valparaiso':\n",
    "        entry = 'Valparaíso'\n",
    "\n",
    "    elif entry == 'VIC':\n",
    "        entry = 'Victória'\n",
    "\n",
    "    elif entry == 'WA':\n",
    "        entry = 'Western Australia'\n",
    "\n",
    "    elif 'Pegar' in entry:\n",
    "        df_darwincore.iloc[cont,41] = adiciona_nova_info(entry,df_darwincore.iloc[cont,41])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan':\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,16] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna municipio\n",
    "cont = 0\n",
    "for entry in df_darwincore['Município']:\n",
    "    if entry.split('(')[-1] == 'EBMAR)':\n",
    "        entry = entry.replace(' (EBMAR)','')\n",
    "        df_darwincore.iloc[cont,21] = adiciona_nova_info('EBMAR',df_darwincore.iloc[cont,21])\n",
    "\n",
    "    elif entry.split(' ')[0] == 'BMOC':\n",
    "        otherCatalogNumbers[cont] = adiciona_nova_info(entry,otherCatalogNumbers[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'Buzios':\n",
    "        entry = entry.replace('Buzios','Búzios')\n",
    "\n",
    "    elif entry == 'Belo horizonte':\n",
    "        entry = entry.title()\n",
    "\n",
    "    elif entry == 'Buenopolis':\n",
    "        entry = 'Buenópolis'\n",
    "    \n",
    "    elif entry == 'Cachoeira do Campo/Ouro Preto':\n",
    "        entry = 'Ouro Preto'\n",
    "        municipality[cont] = adiciona_nova_info('Cachoeira do Campo',municipality[cont])\n",
    "\n",
    "    elif entry.split(' ')[0] == 'Canaa':\n",
    "        entry = entry.replace('Canaa','Canaã')\n",
    "\n",
    "    elif entry == 'Cananeia':\n",
    "        entry = 'Cananéia'\n",
    "\n",
    "    elif entry == 'Carajas':\n",
    "        entry = 'Carajás'\n",
    "\n",
    "    elif entry == 'Carmopolis de Minas' or entry == 'Carmopolis de minas':\n",
    "        entry = 'Carmópolis de Minas'\n",
    "\n",
    "    elif entry == 'Conceicao do Mato Dentro' or entry == 'Conceiçao do Mato Dentro' or entry == 'Conceção do Mato Dentro':\n",
    "        entry = 'Conceição do Mato Dentro'\n",
    "\n",
    "    elif entry == 'Distrito de São Bartolomeu- Ouro Preto':\n",
    "        entry = 'Ouro Preto'\n",
    "        municipality[cont] = 'São Bartolomeu'\n",
    "\n",
    "    elif 'Serra Nova,' in entry:\n",
    "        entry = 'Rio Pardo de Minas'\n",
    "        municipality[cont] = adiciona_nova_info('Serra Nova',municipality[cont])\n",
    "\n",
    "    elif entry == 'Divisa Pompéu/Curvelo':\n",
    "        entry = 'Curvelo | Pompéu'\n",
    "\n",
    "    elif entry.split(' ')[0] == 'Entre':\n",
    "        entry = 'Alegre | Muniz Freire'\n",
    "\n",
    "    elif entry == 'Ilha Bela':\n",
    "        entry = 'Ilhabela'\n",
    "\n",
    "    elif entry == 'itabirito':\n",
    "        entry = 'Itabirito'\n",
    "\n",
    "    elif len(entry.split('/'))>1:\n",
    "        entry = entry.replace('/',' | ')\n",
    "    \n",
    "    elif entry == 'Lagoa santa':\n",
    "        entry = entry.title()\n",
    "\n",
    "    elif entry == 'Luislândia':\n",
    "        entry = 'Luizlândia'\n",
    "\n",
    "    elif entry == 'Macarari':\n",
    "        entry = 'Macarani'\n",
    "\n",
    "    elif entry == 'Mar Báltico' or entry == 'Mar Bálitco':\n",
    "        entry = ''\n",
    "        waterBody[cont] = 'Mar Báltico'\n",
    "\n",
    "    elif entry == 'Morro do pilar':\n",
    "        entry = 'Morro do Pilar'\n",
    "\n",
    "    elif entry == 'Paraupebas':\n",
    "        entry = 'Parauapebas'\n",
    "\n",
    "    elif entry == 'Parnaiba':\n",
    "        entry = 'Parnaíba'\n",
    "\n",
    "    elif entry == 'Parque Estadual do Rio Doce' or entry == 'Prq. N. da Serra Geral':\n",
    "        entry = ''\n",
    "        df_darwincore.iloc[cont,21] = entry\n",
    "\n",
    "    elif entry == 'Pindamonhagaba':\n",
    "        entry = 'Pindamonhangaba'\n",
    "\n",
    "    elif entry == 'Presidente Figuereido':\n",
    "        entry = 'Presidente Figueiredo'\n",
    "\n",
    "    elif entry.split('Rio')[0] == 'Rio':\n",
    "        entry = entry.title()\n",
    "\n",
    "    elif entry.split(' ')[0] == 'S.':\n",
    "        entry = 'São Gonçalo do Rio Abaixo'\n",
    "\n",
    "    elif entry == 'Santa Tereza':\n",
    "        entry = 'Santa Teresa'\n",
    "\n",
    "    elif entry == 'Santana do riacho':\n",
    "        entry = 'Santana do Riacho'\n",
    "\n",
    "    elif entry == 'Sao Luis' or entry == 'São Luis':\n",
    "        entry = 'São Luís'\n",
    "\n",
    "    elif entry == 'São Tomé' or entry == 'Sao Tomé das Letras':\n",
    "        entry = 'São Tomé das Letras'\n",
    "\n",
    "    elif entry == 'Senador Guiomar':\n",
    "        entry = 'Senador Guiomard'\n",
    "\n",
    "    elif entry == 'Vitoria':\n",
    "        entry = 'Vitória'\n",
    "\n",
    "    elif entry == 'Serra do Cipó' or entry == 'Serra do Rola Moça':\n",
    "        locality[cont] = adiciona_nova_info(entry,locality[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif 'De ' in entry:\n",
    "        entry = entry.replace('De ','de ')\n",
    "\n",
    "    elif 'Ines' in entry:\n",
    "        entry = entry.replace('Ines','Inês')\n",
    "\n",
    "    elif entry.split(' ')[0] == 'Sta':\n",
    "        entry = 'Santa Cruz de Cabrália'\n",
    "\n",
    "    elif entry.endswith('?'):\n",
    "        locationRemarks[cont] = adiciona_nova_info(entry,locationRemarks[cont])\n",
    "        entry = entry.replace('?','')\n",
    "\n",
    "    elif 'Pegar' in entry:\n",
    "        df_darwincore.iloc[cont,41] = adiciona_nova_info(entry,df_darwincore.iloc[cont,41])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or entry == 'não disponível':\n",
    "        entry = ''\n",
    "    \n",
    "    df_darwincore.iloc[cont,17] = entry\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna cavidade carste\n",
    "cont = 0\n",
    "for entry in df_darwincore['Cavidade Carste']:\n",
    "    if entry == 'nan':\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,18] = entry\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna codigo carste\n",
    "cont = 0\n",
    "for entry in df_darwincore['Codigo Carste']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,19] = ''\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna projeto carste\n",
    "cont = 0\n",
    "for entry in df_darwincore['Projeto Carste']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,20] = ''\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna localidade\n",
    "cont = 0\n",
    "for entry in df_darwincore['Localidade']:\n",
    "    if (entry in ['A caminho de Vyborg','40 mile Beach','Afloramento Rochoso, Coordenadas imprecisas','Além de Torpederas','Amostra monitoria LAB.',\n",
    "            'Atrás do Ecomares','CAI-03','Caminho da Nascente','Caminho da nascente','CRH','Exterior RM 33','Frag. Florestal','Fragmento Florestal',\n",
    "            'Fragmento de Mata nas proximidades da rodovia MG-010','GEM-1614','GEM 1614','GAND-73','G. N4 E (FLONA) 26/46','há 25 km de Suvorov','LAFCTG-01',\n",
    "            'Ind. PPGT 424 - A. ameira','PDER TREVO','Plastic Bag','ZF2','VL MSS PROP','Beira da estrada, rumo Salinópolis']\n",
    "        or 'Anglo' in entry or 'CSS' in entry or 'GS ' in entry or 'MS-' in entry or 'MCFC-'in entry or 'MGB-' in entry or 'N1N8' in entry\n",
    "        or 'Próx' in entry or 'Prox' in entry.capitalize() or 'SB-' in entry or 'SJL-' in entry or 'SPT-' in entry or 'PRP' in entry\n",
    "        ):\n",
    "        locationRemarks[cont] = adiciona_nova_info(entry,locationRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif 'Abunã' in entry or 'Albunã' in entry:\n",
    "        municipality[cont] = adiciona_nova_info('Abunã',municipality[cont])\n",
    "        entry = entry.replace('Abunã','')\n",
    "        entry = entry.replace('Albunã','')\n",
    "        entry = entry.replace(', ','')\n",
    "        entry = entry.replace(',','')\n",
    "        locationRemarks[cont] = adiciona_nova_info(entry,locationRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif 'Caverna' in entry or 'caverna' in entry:\n",
    "        habitat[cont] = adiciona_nova_info('Caverna',habitat[cont])\n",
    "\n",
    "    elif 'Lago' in entry or 'lago' in entry:\n",
    "        habitat[cont] = adiciona_nova_info('Lagoa',habitat[cont])\n",
    "\n",
    "    elif 'Ilha' in entry or 'Ilhota' in entry:\n",
    "        island[cont] = adiciona_nova_info(entry,island[cont])\n",
    "\n",
    "    elif 'Folhiço' in entry:\n",
    "        df_darwincore.iloc[cont,38] = adiciona_nova_info('Caverna',df_darwincore.iloc[cont,38])\n",
    "        entry = ''\n",
    "\n",
    "    elif 'Distrito' in entry:\n",
    "        municipality[cont] = adiciona_nova_info(entry,municipality[cont])\n",
    "\n",
    "    elif 'Estrada' in entry:\n",
    "        locationRemarks[cont] = adiciona_nova_info(entry,locationRemarks[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif 'Mar Báltico' in entry:\n",
    "        waterBody[cont] = adiciona_nova_info(entry,waterBody[cont])\n",
    "\n",
    "    elif entry in ['Estação Ecológica UFMG','Estação Ecológica da UFMG','Estação Ecológica','Estação Ecológica (UFMG)','Estção Ecológica UFMG','Est. Ecologica UFMG','Estação Ecológica da Universidade Federal de Minas Gerais']:\n",
    "        entry = 'Estação Ecológica da UFMG'\n",
    "\n",
    "    elif entry == 'nan' or entry == 'Equipe Carste et al.' or entry == 'Local de coleta impreciso' or entry == 'Pegar com leopoldo':\n",
    "        entry = ''\n",
    "\n",
    "    if entry == 'Bacia do rio Miño':\n",
    "        entry = 'Bacia do Rio Miño'\n",
    "\n",
    "    if '/' in entry:\n",
    "        entry = entry.replace('/',' | ')\n",
    "\n",
    "    df_darwincore.iloc[cont,21] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna latitude longitude\n",
    "cont = 0\n",
    "for entry in df_darwincore['Lat. - Long. °']:\n",
    "    entry = entry.replace(\"''\",'\"')\n",
    "    entry = entry.replace('º','°')\n",
    "    entry = entry.replace('⁰','°')\n",
    "    entry = entry.replace('°','°')\n",
    "    entry = entry.replace('°','°')\n",
    "    entry = entry.replace('`',\"'\")\n",
    "    entry = entry.replace('\\'',\"'\")\n",
    "    entry = entry.replace('\" ','\"')\n",
    "\n",
    "    if len(entry.split('; '))>1 and '\"' not in entry:\n",
    "        entry = entry.replace(\"'\",\"'00\\\"\")\n",
    "    \n",
    "    if ';4' in entry or '’' in entry:\n",
    "        entry = entry.replace(';4',', 4')\n",
    "        entry = entry.replace('’’','\"')\n",
    "        entry = entry.replace('’','\\'')\n",
    "\n",
    "    if len(entry.split('; '))>1 and 'S' in entry.split('; ')[0] and 'W' in entry.split('; ')[1]:\n",
    "        entry = entry.replace('S','')\n",
    "        entry = entry.replace('°','S',1)\n",
    "        entry = entry.replace('W','')\n",
    "        entry = entry.replace('°','W',1)\n",
    "        verbatimLatitude[cont] = entry.split('; ')[0]\n",
    "        verbatimLongitude[cont] = entry.split('; ')[1]\n",
    "        df_darwincore.iloc[cont,22] = str(entry.split('; ')[1]+', '+entry.split('; ')[0])\n",
    "\n",
    "    elif len(entry.split('; '))>1 and 'S' in entry.split('; ')[0] and 'E' in entry.split('; ')[1]:\n",
    "        entry = entry.replace('S','')\n",
    "        entry = entry.replace('°','S',1)\n",
    "        entry = entry.replace('E','')\n",
    "        entry = entry.replace('°','E',1)\n",
    "        verbatimLatitude[cont] = entry.split('; ')[0]\n",
    "        verbatimLongitude[cont] = entry.split('; ')[1]\n",
    "        df_darwincore.iloc[cont,22] = str(entry.split('; ')[1]+', '+entry.split('; ')[0])\n",
    "\n",
    "    elif len(entry.split('; '))>1 and 'N' in entry.split('; ')[0] and 'E' in entry.split('; ')[1]:\n",
    "        entry = entry.replace('N','')\n",
    "        entry = entry.replace('°','N',1)\n",
    "        entry = entry.replace('E','')\n",
    "        entry = entry.replace('°','E',1)\n",
    "        verbatimLatitude[cont] = entry.split('; ')[0]\n",
    "        verbatimLongitude[cont] = entry.split('; ')[1]\n",
    "        df_darwincore.iloc[cont,22] = str(entry.split('; ')[1]+', '+entry.split('; ')[0])\n",
    "\n",
    "    elif len(entry.split('; '))>1 and 'N' in entry.split('; ')[0] and 'W' in entry.split('; ')[1]:\n",
    "        entry = entry.replace('N','')\n",
    "        entry = entry.replace('°','N',1)\n",
    "        entry = entry.replace('W','')\n",
    "        entry = entry.replace('°','W',1)\n",
    "        verbatimLatitude[cont] = entry.split('; ')[0]\n",
    "        verbatimLongitude[cont] = entry.split('; ')[1]\n",
    "        df_darwincore.iloc[cont,22] = str(entry.split('; ')[1]+', '+entry.split('; ')[0])\n",
    "\n",
    "    elif entry == 'nan' or entry == 'Indisponivel' or entry == 'Desconhecida':\n",
    "        df_darwincore.iloc[cont,22] = ''\n",
    "\n",
    "    elif 'Pegar' in entry or 'Achar' in entry:\n",
    "        df_darwincore.iloc[cont,41] = adiciona_nova_info(entry,df_darwincore.iloc[cont,41])\n",
    "        entry = ''\n",
    "    # if not ('\\'' in entry or '\"' in entry) and entry != '':\n",
    "    #     print(entry)\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colunas graus minutos segundos\n",
    "cont = 0\n",
    "for entry in df_darwincore['Graus']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,23] = ''\n",
    "    cont += 1\n",
    "\n",
    "cont = 0\n",
    "for entry in df_darwincore['Minutos']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,24] = ''\n",
    "    cont += 1\n",
    "\n",
    "cont = 0\n",
    "for entry in df_darwincore['Segundos']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,25] = ''\n",
    "    cont += 1\n",
    "\n",
    "cont = 0\n",
    "for entry in df_darwincore['Sul/Norte']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,26] = ''\n",
    "\n",
    "    if entry == 's' or entry == 'n':\n",
    "        df_darwincore.iloc[cont,26] = entry.capitalize()\n",
    "\n",
    "    cont += 1\n",
    "\n",
    "cont = 0\n",
    "for entry in df_darwincore['Graus.1']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,27] = ''\n",
    "    cont += 1\n",
    "\n",
    "cont = 0\n",
    "for entry in df_darwincore['Minutos.1']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,28] = ''\n",
    "    cont += 1\n",
    "\n",
    "cont = 0\n",
    "for entry in df_darwincore['Segundos.1']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,29] = ''\n",
    "    cont += 1\n",
    "\n",
    "cont = 0\n",
    "for entry in df_darwincore['W/O']:\n",
    "    if entry == 'nan':\n",
    "        df_darwincore.iloc[cont,30] = ''\n",
    "\n",
    "    if entry == 'w' or entry == 'e':\n",
    "        df_darwincore.iloc[cont,30] = entry.capitalize()\n",
    "    \n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colunna decimais lat long\n",
    "cont = 0\n",
    "for entry in df_darwincore['Decimais - Latitude']:\n",
    "    if (\n",
    "        entry == 'nan' or entry == 'Nao Tem' or entry == 'Pegar no material suplementar artigo 2015' or entry == '0.0'\n",
    "        or entry == '0' or 'Indisponivel' in entry\n",
    "    ):\n",
    "        df_darwincore.iloc[cont,31] = ''\n",
    "\n",
    "    if '°' in entry:\n",
    "        entry = entry.replace('°','°')\n",
    "\n",
    "    cont += 1\n",
    "\n",
    "cont = 0\n",
    "for entry in df_darwincore['Decimais - Longitude']:\n",
    "    if entry == 'nan' or entry == 'Nao Tem' or entry == 'Pegar no material suplementar artigo 2015' or 'Indisponivel' in entry:\n",
    "        df_darwincore.iloc[cont,32] = ''\n",
    "    # if (not df_darwincore.iloc[cont,31] != '' or not df_darwincore.iloc[cont,32] != '') and (df_darwincore.iloc[cont,22] != '' or df_darwincore.iloc[cont,23]):\n",
    "    #     print(f\"- tombo:{df_darwincore.iloc[cont,0]} - coord {df_darwincore.iloc[cont,22]} - Graus {df_darwincore.iloc[cont,23]} - Graus{df_darwincore.iloc[cont,27]}\")\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna altitude\n",
    "cont = 0\n",
    "for entry in df_darwincore['Altitude']:\n",
    "    entry = entry.replace('.0','')\n",
    "    entry = entry.replace('.','')\n",
    "    entry = entry.replace(' m','')\n",
    "    entry = entry.replace('m','')\n",
    "    df_darwincore.iloc[cont,33] = entry\n",
    "    if len(entry.split('-'))>1:\n",
    "        minimumElevationInMeters[cont] = entry.split('-')[0]\n",
    "        df_darwincore.iloc[cont,33] = entry.split('-')[1]\n",
    "    \n",
    "    if 'asl' in entry:\n",
    "        df_darwincore.iloc[cont,33] = entry.replace('asl',' masl')\n",
    "\n",
    "    elif entry == 'nan':\n",
    "        df_darwincore.iloc[cont,33] = ''\n",
    "    \n",
    "    if df_darwincore.iloc[cont,33] != '' and not minimumElevationInMeters[cont]:\n",
    "        minimumElevationInMeters[cont] = df_darwincore.iloc[cont,33]\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna data\n",
    "cont = 0\n",
    "for entry in df_darwincore['Data']:\n",
    "    entry = entry.replace('.','/')\n",
    "    entry = entry.replace(';','/')\n",
    "    entry = entry.replace(',','/')\n",
    "    entry = entry.replace('//','/')\n",
    "    entry = entry.replace(' de ','/')\n",
    "    entry = entry.replace('_','-')\n",
    "    entry = entry.replace(' a ','-')\n",
    "    entry = entry.replace('Fevereiro-','02/')\n",
    "    entry = entry.replace('Março','03')\n",
    "    entry = entry.replace('Setembro','07')\n",
    "    entry = entry.replace(' ','')\n",
    "    entry = entry.replace('out','10')\n",
    "    entry = entry.replace('00:00:00','')\n",
    "    if 'XII' in entry.upper() or 'XIII' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('XIII','12')\n",
    "        entry = entry.replace('XII','12')        \n",
    "\n",
    "    if 'XI' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('XI','11')\n",
    "\n",
    "    if 'IX' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('IX','09')\n",
    "\n",
    "    if 'X' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('X','10')\n",
    "\n",
    "    if 'VIII' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('VIII','08')\n",
    "\n",
    "    if 'VII' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('VII','07')\n",
    "\n",
    "    if 'VI' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('VI','06')\n",
    "\n",
    "    if 'IV' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('IV','04')\n",
    "\n",
    "    if 'V' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('V','05')\n",
    "\n",
    "    if 'III' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('III','03')\n",
    "\n",
    "    if 'II' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('II','02')\n",
    "\n",
    "    if 'I' in entry.upper():\n",
    "        entry = entry.upper()\n",
    "        entry = entry.replace('I','01')\n",
    "\n",
    "    entry = muda_data(entry)\n",
    "\n",
    "    if entry == 'nan' or entry == '??' or entry == 'semdados' or entry == 'SPR01NG':\n",
    "        entry = ''\n",
    "\n",
    "    if len(entry.split('-')) == 2:\n",
    "        datainicio = muda_data(entry.split('-')[0])\n",
    "        datafinal = muda_data(entry.split('-')[1])\n",
    "\n",
    "        if len(datainicio.split('-'))<len(datafinal.split('-')):\n",
    "            if len(datainicio.split('-')) == 2 and len(datafinal.split('-')) == 3:\n",
    "                data = datetime.strptime(datafinal,'%Y-%m-%d')\n",
    "                datainicio = str(data.year) + '-' + datainicio\n",
    "\n",
    "            elif len(datainicio.split('-')) == 1 and len(datafinal.split('-')) == 3:\n",
    "                data = datetime.strptime(datafinal,'%Y-%m-%d')\n",
    "                datainicio = str(data.year) + '-' + str(data.month) + '-' + datainicio\n",
    "\n",
    "            elif len(datainicio.split('-')) == 1 and len(datafinal.split('-')) == 2 and len(datafinal.split('-')[0]) == 4:\n",
    "                data = datetime.strptime(datafinal,'%Y-%m')\n",
    "                datainicio = str(data.year) + '-' + datainicio\n",
    "\n",
    "            elif len(datainicio.split('-')) == 1 and len(datafinal.split('-')) == 2 and len(datafinal.split('-')[0]) == 2:\n",
    "                data = datetime.strptime(datafinal,'%m-%d')\n",
    "                datainicio = str(data.month) + '-' + datainicio\n",
    "        \n",
    "        if datainicio == datafinal:\n",
    "            entry = datainicio\n",
    "        else:\n",
    "            entry = datainicio + '/' + datafinal\n",
    "\n",
    "    if entry == '2016-2-8/01/2016-02-04':\n",
    "        entry = '2016-01-08/2016-02-04'\n",
    "\n",
    "    if '-'not in entry and entry != '':\n",
    "        entry = entry.replace('/','-')\n",
    "\n",
    "    df_darwincore.iloc[cont,34] = entry\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna coletores\n",
    "cont = 0\n",
    "lista_coletores = pd.read_csv('nomes.txt',delimiter=':',header=None)\n",
    "lista_coletores = pd.DataFrame(lista_coletores)\n",
    "for entry in df_darwincore['Coletor (es)']:\n",
    "    if ':' in entry:\n",
    "        entry = entry.replace(':','')\n",
    "\n",
    "    if entry in list(lista_coletores[0]):\n",
    "        posicao = list(lista_coletores[0]).index(entry)\n",
    "        entry = lista_coletores.iloc[posicao,1]\n",
    "\n",
    "    if entry == 'nan' or entry == '??' or entry == 'desconhecido':\n",
    "        entry = ''\n",
    "\n",
    "    if 'Preservado' in entry:\n",
    "        preparations[cont] = adiciona_nova_info(entry,preparations[cont])\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,35] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna material tipo\n",
    "cont = 0\n",
    "for entry in df_darwincore['Material tipo']:\n",
    "    if 'Paratipo' in entry or 'Paratype' in entry:\n",
    "        entry = 'Parátipo'\n",
    "\n",
    "    elif 'Holotype' in entry:\n",
    "        entry = 'Holótipo'\n",
    "\n",
    "    elif entry == 'nan' or entry == 'Sim':\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'Lâmina':\n",
    "        preparations[cont] = adiciona_nova_info(entry,preparations[cont])\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,36] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna coletado em\n",
    "cont = 0\n",
    "for entry in df_darwincore['Coletado em']:\n",
    "    if 'Serra Pilheira' in entry or 'Serapilheira' or 'Serra pilheira' in entry or 'Serrapilhera':\n",
    "        entry = entry.replace('Serapilheira','Serrapilheira')\n",
    "        entry = entry.replace('Serrapilhera','Serrapilheira')\n",
    "        entry = entry.replace('Serra Pilheira','Serrapilheira')\n",
    "        entry = entry.replace('Serra pilheira','Serrapilheira')\n",
    "\n",
    "    if ('Caverna' in entry.title() or 'Areia' in entry.title() or 'Agua doce' in entry.capitalize() or 'Amostra' in entry or 'podre' in entry\n",
    "        or 'beira' in entry.lower() or 'arbu' in entry or 'Canto' in entry or 'Casca' in entry or 'Chão' in entry \n",
    "        or 'substrato' in entry.lower() or 'Costão' in entry or 'Concreto' in entry or 'Córrego' in entry or 'Tronco' in entry.title()\n",
    "        or 'Em frente' in entry or 'Entre' in entry or 'Grama' in entry or 'Litoral' in entry or 'rocha' in entry or 'Madeira' in entry\n",
    "        or ('litoral' in entry and 'sublitoral' not in entry) or 'Nascente' in entry or 'Pedras' in entry.title() or 'Piscina' in entry\n",
    "        or 'Poste' in entry or 'Pont' in entry or 'Poça' in entry or 'Riacho' in entry or 'Rio' in entry or 'Serra' in entry.capitalize()\n",
    "        or 'Sedimento' in entry or 'Soil' in entry or 'Solo' in entry.title() or 'Superfície' in entry or 'Vegetação' in entry\n",
    "        or 'lajes' in entry or 'no coletor' in entry or 'plantação' in entry or 'zona' in entry or 'Canga' in entry\n",
    "        or ('água doce' in entry.lower() and ('Oribatida' not in entry or 'Planta' in entry)) or 'corrégo' in entry or 'Cachoeira' in entry\n",
    "        or entry == 'Escorregador' or entry == 'mata' or 'Folha' in entry or 'Folhiço' in entry.title() or entry == 'Guano'\n",
    "        or entry == 'Lado Marinho' or entry == 'Atrás da Marinha' or 'Aviário 5, Armadilha' in entry or entry == 'Piscicultura Lustosa'\n",
    "    ):\n",
    "        habitat[cont] = adiciona_nova_info(entry,habitat[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif 'da via ' in entry or entry == '400 m LO1 saindo NS1' or entry == 'L01 150m NS1' or entry == 'L02 120 m' or entry == 'L02 340 m da NS1':\n",
    "        df_darwincore.iloc[cont,38] = adiciona_nova_info(entry,df_darwincore.iloc[cont,38])\n",
    "        entry = ''\n",
    "\n",
    "    elif 'Euryoryzomys' in entry and not entry.endswith('o)'):\n",
    "        dynamicProperties[cont] = {'coletado':'Macho; Peso: 80g; Comprimento do corpo: 152,0 mm; Orelha: 24 mm; Área: Pit fall 02; Comprimento da cauda: 168,0 mm; Tarso: 36,8 mm; Escrotado; Nº AAP200'}\n",
    "        entry = 'Euryoryzomys cf. Lamia'\n",
    "\n",
    "    elif 's(' in entry or 'tres (' in entry or 'Em ' in entry or 'Host: ' in entry:\n",
    "        entry = entry.replace('s(','s (')\n",
    "        entry = entry.replace('tres (','tris (')\n",
    "        entry = entry.replace('Em ','')\n",
    "        entry = entry.replace('Host: ','')\n",
    "\n",
    "    elif 'altitude' in entry:\n",
    "        entry = entry.replace(', 739 m altitude','')\n",
    "        df_darwincore.iloc[cont,33] = adiciona_nova_info('739',df_darwincore.iloc[cont,33])\n",
    "\n",
    "    elif ('Pitfall' in entry or 'Winkler' in entry or 'Surber' in entry or 'busca ativa' in entry or 'Drifnet' in entry or 'Coleta' in entry.title() or 'Encontrado no alcool' in entry):\n",
    "        df_darwincore.iloc[cont,39] = adiciona_nova_info(entry,df_darwincore.iloc[cont,39])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'Algas verdes, água salobra':\n",
    "        entry = 'Algas verdes'\n",
    "        habitat[cont] = adiciona_nova_info('Água salobra',habitat[cont])\n",
    "\n",
    "    elif entry == 'Intertidal-Algas':\n",
    "        entry = 'Algas'\n",
    "        habitat[cont] = adiciona_nova_info('Intertidal',habitat[cont])\n",
    "\n",
    "    elif entry == 'área de cerrado, sobre cupins':\n",
    "        entry = 'Cupins'\n",
    "        habitat[cont] = adiciona_nova_info('área de cerrado, sobre cupins',habitat[cont])\n",
    "\n",
    "    elif entry == 'Algas diversas acima da linha da maré baixa':\n",
    "        entry = 'Algas'\n",
    "        habitat[cont] = adiciona_nova_info('Acima da linha da maré baixa',habitat[cont])\n",
    "\n",
    "    elif 'Lab de Sistematica' in entry:\n",
    "        df_darwincore.iloc[cont,38] = adiciona_nova_info(entry,df_darwincore.iloc[cont,38])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'próximo a abertura':\n",
    "        temp_dict = dynamicProperties[cont].copy()\n",
    "        temp_dict['zonação'] = entry\n",
    "        dynamicProperties[cont] = temp_dict\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or entry == 'Acaro perdido' or '???' in entry:\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,37] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna observacoes\n",
    "cont = 0\n",
    "for entry in df_darwincore['Observações']:\n",
    "    if 'Bromélia' in entry:\n",
    "        df_darwincore.iloc[cont,37] = adiciona_nova_info('Bromélia',df_darwincore.iloc[cont,37])\n",
    "\n",
    "    elif 'caverna' in entry.lower() or 'Canga' in entry or 'Mata' in entry:\n",
    "        habitat[cont] = adiciona_nova_info(entry,habitat[cont])\n",
    "\n",
    "    elif 'Winkler' in entry.capitalize() or 'coleta ativa' in entry.lower():\n",
    "        df_darwincore.iloc[cont,39] = adiciona_nova_info(entry,df_darwincore.iloc[cont,39])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan':\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,38] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna metodo de coleta\n",
    "cont = 0\n",
    "for entry in df_darwincore['Método de coleta']:\n",
    "    entry = entry.replace('Arm.','Armadilha')\n",
    "    if entry.capitalize() == 'Ativa':\n",
    "        entry = 'Busca ativa'\n",
    "\n",
    "    elif (\n",
    "        'Busca ativa' in entry.capitalize() or 'Coleta ativa' in entry.capitalize() or 'Coleta manual' in entry.capitalize()\n",
    "        or 'Guarda chuva entomológico' in entry.capitalize() or 'Lençol entomológico' in entry.capitalize()\n",
    "        or 'Alga lavada' in entry.capitalize() or 'Coleta noturna' in entry.capitalize() or 'Ponto' in entry.capitalize()\n",
    "    ):\n",
    "        entry = entry.capitalize()\n",
    "\n",
    "    elif entry == 'Guardachuva entomológico':\n",
    "        entry = 'Guarda chuva entomológico'\n",
    "\n",
    "    elif entry == 'Pit fall':\n",
    "        entry = 'Pitfall'\n",
    "\n",
    "    elif entry.capitalize() == 'Rede-de-neblina':\n",
    "        entry = 'Rede de neblina'\n",
    "\n",
    "    elif entry == 'Wincker' or entry == 'Winckler' or entry == 'winkler':\n",
    "        entry = 'Winkler'\n",
    "\n",
    "    elif 'Suber' in entry:\n",
    "        entry = 'Surber'\n",
    "    \n",
    "    elif 'Malase' in entry or 'Malayse' in entry:\n",
    "        entry = 'Malaise'\n",
    "\n",
    "    if 'caverna' in entry:\n",
    "        habitat[cont] = adiciona_nova_info(entry,habitat[cont])\n",
    "\n",
    "    if 'Canga' in entry:\n",
    "        entry = entry.replace('Canga. ','')\n",
    "        df_darwincore.iloc[cont,37] = adiciona_nova_info('Canga',df_darwincore.iloc[cont,37])\n",
    "\n",
    "    if 'Árvore' in entry:\n",
    "        entry = entry.replace('Árvore podre,','')\n",
    "        df_darwincore.iloc[cont,37] = adiciona_nova_info('Árvore podre',df_darwincore.iloc[cont,37])\n",
    "\n",
    "    if 'Folhiço' in entry:\n",
    "        habitat[cont] = adiciona_nova_info('Folhiço',habitat[cont])\n",
    "        entry = entry.replace('Folhiço, extraído com ','')\n",
    "\n",
    "    if 'Musgo' in entry:\n",
    "        habitat[cont] = adiciona_nova_info('Musgo',habitat[cont])\n",
    "        entry = entry.replace('Musgo /','')\n",
    "\n",
    "    elif entry == 'nan' or entry == 'não disponível':\n",
    "        entry = ''\n",
    "\n",
    "    if ' ,' in entry or ';' in entry or 'nan | ' in entry:\n",
    "        entry = entry.replace(' ,',',')\n",
    "        entry = entry.replace(';',',')\n",
    "        entry = entry.replace('nan | ','')\n",
    "\n",
    "    df_darwincore.iloc[cont,39] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna numero de anilha\n",
    "cont = 0\n",
    "for entry in df_darwincore['Número da anilha']:\n",
    "    if 'busca' in entry:\n",
    "        df_darwincore.iloc[cont,39] = adiciona_nova_info(entry.capitalize(),df_darwincore.iloc[cont,39])\n",
    "        entry = ''\n",
    "    \n",
    "    elif 'mata' in entry or 'sobre' in entry:\n",
    "        habitat[cont] = adiciona_nova_info(entry,habitat[cont])\n",
    "        entry = ''\n",
    "\n",
    "    elif 'sobre pedras' in entry:\n",
    "        print(entry)\n",
    "        df_darwincore.iloc[cont,38] = adiciona_nova_info(entry,df_darwincore.iloc[cont,38])\n",
    "        entry = ''\n",
    "\n",
    "    elif entry == 'nan' or entry == 'r':\n",
    "        entry = ''\n",
    "    \n",
    "    if entry != '':\n",
    "        temp_dict = dynamicProperties[cont].copy()\n",
    "        temp_dict['numero_anilha'] = entry\n",
    "        dynamicProperties[cont] = temp_dict\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,40] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna emprestimos\n",
    "cont = 0\n",
    "for entry in df_darwincore['Empréstimos']:\n",
    "    if entry == 'nan':\n",
    "        entry = ''\n",
    "    \n",
    "    if 'nan | ' in entry:\n",
    "        entry = entry.replace('nan | ','')\n",
    "\n",
    "    df_darwincore.iloc[cont,41] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna etiqueta\n",
    "cont = 0\n",
    "for entry in df_darwincore['Etiqueta']:\n",
    "    if entry == 'nan':\n",
    "        entry = ''\n",
    "    \n",
    "    df_darwincore.iloc[cont,42] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna sequencias anexos\n",
    "cont = 0\n",
    "for entry in df_darwincore['Sequencias e Anexos']:\n",
    "    if entry == 'nan' or 'https://' in entry:\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,43] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colunas zonacao e estacao\n",
    "cont = 0\n",
    "for entry in df_darwincore['Zonação']:\n",
    "    if entry == 'Afótico':\n",
    "        entry = 'Afótica'\n",
    "\n",
    "    elif entry == 'PC':\n",
    "        entry = 'Penumbra clara'\n",
    "\n",
    "    elif entry == 'nan':\n",
    "        entry = ''\n",
    "\n",
    "    if entry != '':\n",
    "        temp_dict = dynamicProperties[cont].copy()\n",
    "        temp_dict['zonação'] = entry\n",
    "        dynamicProperties[cont] = temp_dict\n",
    "\n",
    "    df_darwincore.iloc[cont,44] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "for entry in df_darwincore['Estação']:\n",
    "    if entry == 'nan':\n",
    "        entry = ''\n",
    "    \n",
    "    if entry == 'Umida':\n",
    "        entry = 'Úmida'\n",
    "    \n",
    "    if entry != '':\n",
    "        temp_dict = dynamicProperties[cont].copy()\n",
    "        temp_dict['estação'] = entry\n",
    "        dynamicProperties[cont] = temp_dict\n",
    "    \n",
    "    df_darwincore.iloc[cont,45] = entry.capitalize()\n",
    "    cont += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "for entry in df_darwincore['Sequencias Gen Bank']:\n",
    "    entry = entry.replace('/','|')\n",
    "    if entry == 'nan':\n",
    "        entry = ''\n",
    "\n",
    "    df_darwincore.iloc[cont,46] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Dependent Columns\n",
    "\n",
    "This part of the code processes dependent columns in the DataFrame (`df_darwincore`), specifically focusing on constructing scientific names and assigning taxon ranks based on the hierarchy of biological classification. The goal is to ensure that the correct taxon rank is assigned based on the availability of classification data in the DataFrame.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- **Construct Scientific Names**: Combine different levels of taxonomic classification to create a complete scientific name.\n",
    "  \n",
    "- **Assign Taxon Ranks**: Determine the appropriate taxon rank (such as species, genus, family, etc.) based on the available classification data.\n",
    "\n",
    "### Functionality\n",
    "\n",
    "1. **Initialization**: \n",
    "   - A control variable `cont` is initialized to 0, which is used to iterate over the entries in the taxon ranks.\n",
    "\n",
    "2. **Loop Over Taxon Ranks**:\n",
    "   - A `for` loop iterates through the `taxonRank` list, checking the availability of classification data in the DataFrame for each entry.\n",
    "\n",
    "3. **Conditions and Assignments**:\n",
    "   - Each `if` condition checks for the presence of classification data in the corresponding columns of the DataFrame (`df_darwincore`).\n",
    "   - If data is present for the lowest taxon rank (species), the scientific name is constructed by combining the species and genus names. The taxon rank is set to \"Espécie\" (Species).\n",
    "   - If the species name is not available but the genus name is, the scientific name is assigned as the genus name, and the taxon rank is set to \"Gênero\" (Genus).\n",
    "   - This pattern continues up the taxonomic hierarchy, assigning ranks for subfamily, family, superfamily, cohort, suborder, order, and class as needed.\n",
    "   - If no lower taxon ranks are available, the scientific name is set to the value from the `classe` list, with the taxon rank assigned as \"Classe\" (Class).\n",
    "\n",
    "4. **Incrementing the Counter**:\n",
    "   - After processing each entry, the `cont` variable is incremented to move to the next entry in the DataFrame.\n",
    "\n",
    "### Final Considerations\n",
    "\n",
    "This code segment is crucial for correctly assigning taxonomic classifications in the context of biodiversity data, ensuring that hierarchical relationships are maintained and that complete scientific names are available for analysis and reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adicionar ultima classificacao na lista e apagar espaços sobrando\n",
    "cont = 0\n",
    "for i in taxonRank:\n",
    "    if df_darwincore.iloc[cont,10]:\n",
    "        scientificName[cont] = df_darwincore.iloc[cont,9] + ' ' + df_darwincore.iloc[cont,10]\n",
    "        taxonRank[cont] = 'Espécie'\n",
    "\n",
    "    elif df_darwincore.iloc[cont,9]:\n",
    "        scientificName[cont] = df_darwincore.iloc[cont,9]\n",
    "        taxonRank[cont] = 'Gênero'\n",
    "    \n",
    "    elif df_darwincore.iloc[cont,8]:\n",
    "        scientificName[cont] = df_darwincore.iloc[cont,8]\n",
    "        taxonRank[cont] = 'Subfamília'\n",
    "    \n",
    "    elif df_darwincore.iloc[cont,7]:\n",
    "        scientificName[cont] = df_darwincore.iloc[cont,7]\n",
    "        taxonRank[cont] = 'Família'\n",
    "\n",
    "    elif df_darwincore.iloc[cont,6]:\n",
    "        scientificName[cont] = df_darwincore.iloc[cont,6]\n",
    "        taxonRank[cont] = 'Superfamília'\n",
    "\n",
    "    elif df_darwincore.iloc[cont,5]:\n",
    "        scientificName[cont] = df_darwincore.iloc[cont,5]\n",
    "        taxonRank[cont] = 'Coorte'\n",
    "\n",
    "    elif df_darwincore.iloc[cont,4]:\n",
    "        scientificName[cont] = df_darwincore.iloc[cont,4]\n",
    "        taxonRank[cont] = 'Subordem'\n",
    "\n",
    "    elif df_darwincore.iloc[cont,3]:\n",
    "        scientificName[cont] = df_darwincore.iloc[cont,3]\n",
    "        taxonRank[cont] = 'Ordem'\n",
    "\n",
    "    else:\n",
    "        scientificName[cont] = classe[cont]\n",
    "        taxonRank[cont] = 'Classe'\n",
    "    cont += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Higher Classification\n",
    "\n",
    "This part of the code processes higher taxonomic classifications in the DataFrame (`df_darwincore`). It constructs a formatted string that represents the hierarchical classification of each entry, ensuring that the scientific names and classifications are correctly organized.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- **Construct Higher Classification**: Combine different levels of taxonomic hierarchy into a single formatted string for each entry.\n",
    "  \n",
    "- **Maintain Taxonomic Relationships**: Ensure that higher classifications (such as kingdom, phylum, class, etc.) are correctly linked to their corresponding species or genus.\n",
    "\n",
    "### Functionality\n",
    "\n",
    "1. **Initialization**: \n",
    "   - A control variable `cont` is initialized to 0 to iterate through each entry in the `higherClassification` list.\n",
    "\n",
    "2. **Loop Over Higher Classification**:\n",
    "   - A `for` loop iterates through the `higherClassification` list.\n",
    "\n",
    "3. **Species Name Construction**:\n",
    "   - If both the genus (column 9) and species (column 10) are available in the DataFrame, the scientific name is constructed by concatenating these two names. \n",
    "   - If either name is missing, the variable `especie` is set to an empty string.\n",
    "\n",
    "4. **Initial Classification**:\n",
    "   - The `classifique` variable is initialized with the value from the `classe` list for the current entry.\n",
    "\n",
    "5. **Appending Higher Classifications**:\n",
    "   - A nested `for` loop iterates through columns 3 to 10 of the DataFrame to append any available classification data to the `classifique` variable.\n",
    "   - The constructed species name (`especie`) is appended to the `classifique` list.\n",
    "\n",
    "6. **Inserting Phylum and Kingdom**:\n",
    "   - The `phylum` and `kingdom` values for the current entry are inserted at the beginning of the `classifique` array.\n",
    "\n",
    "7. **Formatting the Classification String**:\n",
    "   - A formatted string is created by joining all items in the `classifique` array with \" | \" as the separator. \n",
    "   - Any instances of the \"|\" character in the items are replaced with \"/\", and empty items are left as is.\n",
    "\n",
    "8. **Updating Higher Classification**:\n",
    "   - The formatted string is assigned back to the `higherClassification` list for the current entry.\n",
    "\n",
    "9. **Incrementing the Counter**:\n",
    "   - The `cont` variable is incremented to move to the next entry in the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "for i in higherClassification:\n",
    "    if df_darwincore.iloc[cont,9] and df_darwincore.iloc[cont,10]:\n",
    "        especie = df_darwincore.iloc[cont,9] + ' ' + df_darwincore.iloc[cont,10]\n",
    "    else:\n",
    "        especie = ''\n",
    "    classifique = classe[cont]\n",
    "    for i in range(3,10):\n",
    "        if df_darwincore.iloc[cont,i]:\n",
    "            classifique = np.append(classifique,df_darwincore.iloc[cont,i])\n",
    "    classifique = np.append(classifique,especie)\n",
    "    classifique = np.insert(classifique,0,phylum[cont])\n",
    "    classifique = np.insert(classifique,0,kingdom[cont])\n",
    "    formatted_string = ' | '.join(str(item.replace('|','/')) if item else '' for item in classifique)\n",
    "    higherClassification[cont] = formatted_string\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nova coluna habitats\n",
    "cont=0\n",
    "for entry in habitat:\n",
    "    entry = entry.capitalize()\n",
    "    if 'Agua' in entry:\n",
    "        entry = entry.replace('Agua','Água')\n",
    "\n",
    "    elif 'Corrégo' in entry:\n",
    "        entry = entry.replace('Corrégo','Córrego')\n",
    "\n",
    "    elif entry.endswith(']') and '[' not in entry:\n",
    "        entry = entry.replace(']','')\n",
    "\n",
    "    habitat[cont] = entry\n",
    "    cont += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apagar espaços a mais\n",
    "for coluna in listacoluna:\n",
    "    df_darwincore[coluna] = df_darwincore[coluna].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Columns in DataFrame and Saving to CSV\n",
    "\n",
    "This section of the code renames specific columns in the DataFrame (`df_darwincore`) to ensure they align with the Darwin Core (DwC) standards. Following the renaming, the updated DataFrame is saved as a CSV file.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- **Standardize Column Names**: Rename columns in the DataFrame to match the Darwin Core format, facilitating easier data integration and analysis.\n",
    "  \n",
    "- **Save Data**: Export the modified DataFrame to a CSV file for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alterar nome coluna\n",
    "df_darwincore.rename(\n",
    "    columns={\n",
    "        'Tombo':'catalogNumber','Exempl.':'individualCount','Ordem':'order','Superfamília':'superfamily','Família':'family',\n",
    "        'Subfamilia':'subfamily','Material tipo':'typeStatus','Gênero':'genus','Espécie':'specificEpithet',\n",
    "        'Autor e ano':'scientificNameAuthorShip','Determinador':'identifiedBy','Ano determinação':'dateIdentified','País':'country',\n",
    "        'Graus':'graus','Minutos':'minutos','Segundos':'segundos','Graus.1':'graus.1','Minutos.1':'minutos.1','Segundos.1':'segundos.1',\n",
    "        'U.F./Província/Região':'stateProvince','Município':'county','Localidade':'locality','Sul/Norte':'S/N',\n",
    "        'Lat. - Long. °':'verbatimCoordinates','Decimais - Latitude':'decimalLatitude','Decimais - Longitude':'decimalLongitude',\n",
    "        'Data':'eventDate','Coletor (es)':'recordedBy','Altitude':'maximumElevationInMeters','Coletado em':'associatedTaxa',\n",
    "        'Método de coleta':'samplingProtocol','Observações':'eventRemarks','Sequencias Gen Bank':'associatedSequences'\n",
    "    },inplace=True\n",
    ")\n",
    "\n",
    "df_darwincore.to_csv('planilha_original.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer novo df com as colunas certas\n",
    "darwin_core = [\n",
    "    pd.DataFrame(basisOfRecord,columns=['basisOfRecord']),pd.DataFrame(modified,columns=['modified']),\n",
    "    pd.DataFrame(datasetName,columns=['datasetName']),pd.DataFrame(tipe,columns=['type']),pd.DataFrame(language,columns=['language']),\n",
    "    pd.DataFrame(institutionCode,columns=['institutionCode']),pd.DataFrame(collectionCode,columns=['collectionCode']),\n",
    "    pd.DataFrame(license,columns=['license']),pd.DataFrame(rightsHolder,columns=['rightsHolder']),\n",
    "    pd.DataFrame([str(entry) for entry in dynamicProperties],columns=['dynamicProperties']),pd.DataFrame(occurrenceID,columns=['occurrenceID']),\n",
    "    df_darwincore['catalogNumber'],pd.DataFrame(otherCatalogNumbers,columns=['otherCatalogNumbers']),df_darwincore['recordedBy'],\n",
    "    df_darwincore['individualCount'],pd.DataFrame(sex,columns=['sex']),pd.DataFrame(stage,columns=['lifeStage']),\n",
    "    pd.DataFrame(preparations,columns=['preparations']),pd.DataFrame(disposition,columns=['disposition']),df_darwincore['associatedTaxa'],\n",
    "    df_darwincore['associatedSequences'],pd.DataFrame(occurrenceRemarks,columns=['occurrenceRemarks']),df_darwincore['eventDate'],\n",
    "    pd.DataFrame(habitat,columns=['habitat']),df_darwincore['samplingProtocol'],pd.DataFrame(samplingEffort,columns=['samplingEffort']),\n",
    "    df_darwincore['eventRemarks'],pd.DataFrame(continent,columns=['continent']),df_darwincore['country'],\n",
    "    pd.DataFrame(countryCode,columns=['countryCode']),df_darwincore['stateProvince'],df_darwincore['county'],\n",
    "    pd.DataFrame(municipality,columns=['municipality']),pd.DataFrame(waterBody,columns=['waterBody']),df_darwincore['locality'],\n",
    "    pd.DataFrame(locationRemarks,columns=['locationRemarks']),pd.DataFrame(island,columns=['island']),\n",
    "    pd.DataFrame(minimumElevationInMeters,columns=['minimumElevationInMeters']),df_darwincore['maximumElevationInMeters'],\n",
    "    pd.DataFrame(verbatimLatitude,columns=['verbatimLatitude']),pd.DataFrame(verbatimLongitude,columns=['verbatimLongitude']),\n",
    "    df_darwincore['graus'],df_darwincore['minutos'],df_darwincore['segundos'],df_darwincore['S/N'],df_darwincore['graus.1'],\n",
    "    df_darwincore['minutos.1'],df_darwincore['segundos.1'],df_darwincore['W/O'],df_darwincore['verbatimCoordinates'],\n",
    "    df_darwincore['decimalLatitude'],df_darwincore['decimalLongitude'],pd.DataFrame(kingdom,columns=['kingdom']),\n",
    "    pd.DataFrame(phylum,columns=['phylum']),pd.DataFrame(classe,columns=['class']),df_darwincore['order'],df_darwincore['Subordem'],\n",
    "    df_darwincore['Coorte ou Supercoorte'],df_darwincore['superfamily'],df_darwincore['family'],df_darwincore['subfamily'],\n",
    "    df_darwincore['genus'],pd.DataFrame(subgenus,columns=['subgenus']),df_darwincore['specificEpithet'],\n",
    "    pd.DataFrame(infraspecificEpithet,columns=['infraspecificEpithet']),pd.DataFrame(scientificName,columns=['scientificName']),\n",
    "    df_darwincore['scientificNameAuthorShip'],pd.DataFrame(taxonRank,columns=['taxonRank']),\n",
    "    pd.DataFrame(higherClassification,columns=['higherClassification']),pd.DataFrame(vernacularName,columns=['vernacularName']),\n",
    "    pd.DataFrame(taxonRemarks,columns=['taxonRemarks']),pd.DataFrame(identificationQualifier,columns=['identificationQualifier']),\n",
    "    df_darwincore['typeStatus'],df_darwincore['identifiedBy'],df_darwincore['dateIdentified'],\n",
    "    pd.DataFrame(identificationRemarks,columns=['identificationRemarks'])\n",
    "]\n",
    "darwin_core = pd.concat(darwin_core,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,entry in enumerate(darwin_core['dynamicProperties']):\n",
    "    if entry == '{}':\n",
    "        darwin_core['dynamicProperties'][i] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_core.to_csv('planilha_unificada.csv',index=False)\n",
    "# darwin_core.to_excel('planilha_unificada.xlsx',index=False)\n",
    "darwin_core.to_csv('familias/planilha_unificada.csv',index=False)\n",
    "darwin_core.to_csv('../mapas/planilha_unificada.csv',index=False)\n",
    "darwin_core.to_csv('graficos/planilha_unificada.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e86e659cc4c7e7c8281f4dfa198d26eba569ed7d4f5779d5419dff2bd0d92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
